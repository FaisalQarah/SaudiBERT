{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 06:30:40.318072: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-01 06:30:40.341935: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-01 06:30:40.696972: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['text', 'Sentiment'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ÿ≠ŸÇŸàŸÇ ÿßŸÑŸÖÿ±ÿ£ÿ© üíöüíöüíö https://t.co/Mzf90Ta5g1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @___IHAVENOIDEA: ÿ≠ŸÇŸàŸÇ ÿßŸÑŸÖÿ±ÿ£ÿ© ŸÅŸä ÿßŸÑÿ•ÿ≥ŸÑÿßŸÖ. https://t.co/ps3qNw1CbB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @saud_talep: Retweeted ŸÑÿ¨ŸÜÿ© ÿßŸÑÿ™ŸÜŸÖŸäÿ© ÿ®ÿ¥ÿ®ÿ±ÿß (@Shubratanmyeh):\\n \\n ŸÖÿß ÿ≤ÿßŸÑ ÿßŸÑÿ™ÿ≥ÿ¨ŸäŸÑ ŸÖÿ≥ÿ™ŸÖÿ± ŸÅŸä ÿØŸàÿ±ÿ© ÿ≠ŸÇŸàŸÇ ÿßŸÑŸÖÿ±ÿ£ÿ© ÿ®ÿπÿØ ÿßŸÑÿ∑ŸÑÿßŸÇ ‚ú® #ŸàÿπŸäŸÉ_Ÿäÿ≠ŸÖŸäŸÉ... https://t.co/c2NXzNCdLU</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @MojKsa: ÿ≠ŸÇŸàŸÇ ÿßŸÑŸÖÿ±ÿ£ÿ© ÿßŸÑÿ™Ÿä ÿ™ÿ∂ŸÖŸÜŸáÿß ŸÑŸáÿß Ÿàÿ≤ÿßÿ±ÿ© ÿßŸÑÿπÿØŸÑ https://t.co/QUGzWwubFk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                               text   \n",
       "0                                                                                                                           ÿ≠ŸÇŸàŸÇ ÿßŸÑŸÖÿ±ÿ£ÿ© üíöüíöüíö https://t.co/Mzf90Ta5g1  \\\n",
       "1                                                                                               RT @___IHAVENOIDEA: ÿ≠ŸÇŸàŸÇ ÿßŸÑŸÖÿ±ÿ£ÿ© ŸÅŸä ÿßŸÑÿ•ÿ≥ŸÑÿßŸÖ. https://t.co/ps3qNw1CbB   \n",
       "2  RT @saud_talep: Retweeted ŸÑÿ¨ŸÜÿ© ÿßŸÑÿ™ŸÜŸÖŸäÿ© ÿ®ÿ¥ÿ®ÿ±ÿß (@Shubratanmyeh):\\n \\n ŸÖÿß ÿ≤ÿßŸÑ ÿßŸÑÿ™ÿ≥ÿ¨ŸäŸÑ ŸÖÿ≥ÿ™ŸÖÿ± ŸÅŸä ÿØŸàÿ±ÿ© ÿ≠ŸÇŸàŸÇ ÿßŸÑŸÖÿ±ÿ£ÿ© ÿ®ÿπÿØ ÿßŸÑÿ∑ŸÑÿßŸÇ ‚ú® #ŸàÿπŸäŸÉ_Ÿäÿ≠ŸÖŸäŸÉ... https://t.co/c2NXzNCdLU   \n",
       "3                                                                                       RT @MojKsa: ÿ≠ŸÇŸàŸÇ ÿßŸÑŸÖÿ±ÿ£ÿ© ÿßŸÑÿ™Ÿä ÿ™ÿ∂ŸÖŸÜŸáÿß ŸÑŸáÿß Ÿàÿ≤ÿßÿ±ÿ© ÿßŸÑÿπÿØŸÑ https://t.co/QUGzWwubFk   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3401\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 851\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02-twitter, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.496600</td>\n",
       "      <td>0.390134</td>\n",
       "      <td>0.809636</td>\n",
       "      <td>0.809623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.310200</td>\n",
       "      <td>0.315659</td>\n",
       "      <td>0.854289</td>\n",
       "      <td>0.854120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.249700</td>\n",
       "      <td>0.220650</td>\n",
       "      <td>0.910693</td>\n",
       "      <td>0.909148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.215986</td>\n",
       "      <td>0.921269</td>\n",
       "      <td>0.918745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.219900</td>\n",
       "      <td>0.232633</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.910060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>0.155818</td>\n",
       "      <td>0.942421</td>\n",
       "      <td>0.941292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.189583</td>\n",
       "      <td>0.936545</td>\n",
       "      <td>0.935365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.173687</td>\n",
       "      <td>0.938895</td>\n",
       "      <td>0.937458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>0.167946</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.938683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.187269</td>\n",
       "      <td>0.935370</td>\n",
       "      <td>0.933777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.168926</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.199993</td>\n",
       "      <td>0.937720</td>\n",
       "      <td>0.935832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.194164</td>\n",
       "      <td>0.948296</td>\n",
       "      <td>0.947229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.053400</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>0.942421</td>\n",
       "      <td>0.941130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.211302</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.253128</td>\n",
       "      <td>0.936545</td>\n",
       "      <td>0.934806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.211875</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.944793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.222684</td>\n",
       "      <td>0.947121</td>\n",
       "      <td>0.945936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.244339</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.938403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.218094</td>\n",
       "      <td>0.948296</td>\n",
       "      <td>0.947156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.227877</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.233763</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.250497</td>\n",
       "      <td>0.941246</td>\n",
       "      <td>0.939729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.238301</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.944675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.227841</td>\n",
       "      <td>0.948296</td>\n",
       "      <td>0.947118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.224202</td>\n",
       "      <td>0.950646</td>\n",
       "      <td>0.949558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.225166</td>\n",
       "      <td>0.949471</td>\n",
       "      <td>0.948339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02-twitter, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.520800</td>\n",
       "      <td>0.373713</td>\n",
       "      <td>0.839013</td>\n",
       "      <td>0.838838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.297400</td>\n",
       "      <td>0.292644</td>\n",
       "      <td>0.881316</td>\n",
       "      <td>0.880836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.242100</td>\n",
       "      <td>0.233529</td>\n",
       "      <td>0.910693</td>\n",
       "      <td>0.909313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.249200</td>\n",
       "      <td>0.263727</td>\n",
       "      <td>0.902468</td>\n",
       "      <td>0.898414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.192574</td>\n",
       "      <td>0.931845</td>\n",
       "      <td>0.930292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.159957</td>\n",
       "      <td>0.937720</td>\n",
       "      <td>0.936739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.200768</td>\n",
       "      <td>0.931845</td>\n",
       "      <td>0.930138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.938895</td>\n",
       "      <td>0.937718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.160826</td>\n",
       "      <td>0.942421</td>\n",
       "      <td>0.941292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.185811</td>\n",
       "      <td>0.937720</td>\n",
       "      <td>0.936038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.165153</td>\n",
       "      <td>0.942421</td>\n",
       "      <td>0.941513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.180423</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.938547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.185040</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.945078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.199936</td>\n",
       "      <td>0.949471</td>\n",
       "      <td>0.948147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.185984</td>\n",
       "      <td>0.948296</td>\n",
       "      <td>0.947193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.175798</td>\n",
       "      <td>0.950646</td>\n",
       "      <td>0.949728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.179392</td>\n",
       "      <td>0.948296</td>\n",
       "      <td>0.947080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.180710</td>\n",
       "      <td>0.950646</td>\n",
       "      <td>0.949628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.189499</td>\n",
       "      <td>0.947121</td>\n",
       "      <td>0.945936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.202387</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.207597</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.213396</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.220456</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.222204</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.222872</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.944793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.223628</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.944793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.223668</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02-twitter, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.520800</td>\n",
       "      <td>0.373713</td>\n",
       "      <td>0.839013</td>\n",
       "      <td>0.838838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.297400</td>\n",
       "      <td>0.292644</td>\n",
       "      <td>0.881316</td>\n",
       "      <td>0.880836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.242100</td>\n",
       "      <td>0.233529</td>\n",
       "      <td>0.910693</td>\n",
       "      <td>0.909313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.249200</td>\n",
       "      <td>0.263727</td>\n",
       "      <td>0.902468</td>\n",
       "      <td>0.898414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.192574</td>\n",
       "      <td>0.931845</td>\n",
       "      <td>0.930292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.159957</td>\n",
       "      <td>0.937720</td>\n",
       "      <td>0.936739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.200768</td>\n",
       "      <td>0.931845</td>\n",
       "      <td>0.930138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.938895</td>\n",
       "      <td>0.937718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.160826</td>\n",
       "      <td>0.942421</td>\n",
       "      <td>0.941292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.185811</td>\n",
       "      <td>0.937720</td>\n",
       "      <td>0.936038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.165153</td>\n",
       "      <td>0.942421</td>\n",
       "      <td>0.941513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.180423</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.938547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.185040</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.945078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.199936</td>\n",
       "      <td>0.949471</td>\n",
       "      <td>0.948147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.185984</td>\n",
       "      <td>0.948296</td>\n",
       "      <td>0.947193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.175798</td>\n",
       "      <td>0.950646</td>\n",
       "      <td>0.949728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.179392</td>\n",
       "      <td>0.948296</td>\n",
       "      <td>0.947080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.180710</td>\n",
       "      <td>0.950646</td>\n",
       "      <td>0.949628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.189499</td>\n",
       "      <td>0.947121</td>\n",
       "      <td>0.945936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.202387</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.207597</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.213396</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.220456</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.222204</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.222872</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.944793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.223628</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.944793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.223668</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-da, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.639600</td>\n",
       "      <td>0.519764</td>\n",
       "      <td>0.733255</td>\n",
       "      <td>0.693047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>0.442940</td>\n",
       "      <td>0.802585</td>\n",
       "      <td>0.802487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.381600</td>\n",
       "      <td>0.335722</td>\n",
       "      <td>0.850764</td>\n",
       "      <td>0.848840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.293777</td>\n",
       "      <td>0.867215</td>\n",
       "      <td>0.865280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>0.295434</td>\n",
       "      <td>0.862515</td>\n",
       "      <td>0.859332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.355712</td>\n",
       "      <td>0.861340</td>\n",
       "      <td>0.855505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.333219</td>\n",
       "      <td>0.863690</td>\n",
       "      <td>0.856136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.248706</td>\n",
       "      <td>0.893067</td>\n",
       "      <td>0.890592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.276222</td>\n",
       "      <td>0.881316</td>\n",
       "      <td>0.879913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.143300</td>\n",
       "      <td>0.286438</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.890952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.241953</td>\n",
       "      <td>0.889542</td>\n",
       "      <td>0.887487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.399037</td>\n",
       "      <td>0.900118</td>\n",
       "      <td>0.897002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.378772</td>\n",
       "      <td>0.902468</td>\n",
       "      <td>0.900989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.882491</td>\n",
       "      <td>0.882068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.330804</td>\n",
       "      <td>0.904818</td>\n",
       "      <td>0.902887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.421129</td>\n",
       "      <td>0.895417</td>\n",
       "      <td>0.890744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.411227</td>\n",
       "      <td>0.902468</td>\n",
       "      <td>0.901980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.345459</td>\n",
       "      <td>0.908343</td>\n",
       "      <td>0.905831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.362042</td>\n",
       "      <td>0.908343</td>\n",
       "      <td>0.906638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.360563</td>\n",
       "      <td>0.914219</td>\n",
       "      <td>0.912358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.361880</td>\n",
       "      <td>0.914219</td>\n",
       "      <td>0.912478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.401112</td>\n",
       "      <td>0.907168</td>\n",
       "      <td>0.904353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.401243</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.911851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.396301</td>\n",
       "      <td>0.920094</td>\n",
       "      <td>0.918274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.397522</td>\n",
       "      <td>0.920094</td>\n",
       "      <td>0.918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.401370</td>\n",
       "      <td>0.915394</td>\n",
       "      <td>0.914086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.403330</td>\n",
       "      <td>0.914219</td>\n",
       "      <td>0.912918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-da, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.639600</td>\n",
       "      <td>0.519764</td>\n",
       "      <td>0.733255</td>\n",
       "      <td>0.693047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>0.442940</td>\n",
       "      <td>0.802585</td>\n",
       "      <td>0.802487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.381600</td>\n",
       "      <td>0.335722</td>\n",
       "      <td>0.850764</td>\n",
       "      <td>0.848840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.293777</td>\n",
       "      <td>0.867215</td>\n",
       "      <td>0.865280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>0.295434</td>\n",
       "      <td>0.862515</td>\n",
       "      <td>0.859332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.355712</td>\n",
       "      <td>0.861340</td>\n",
       "      <td>0.855505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.333219</td>\n",
       "      <td>0.863690</td>\n",
       "      <td>0.856136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.248706</td>\n",
       "      <td>0.893067</td>\n",
       "      <td>0.890592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.276222</td>\n",
       "      <td>0.881316</td>\n",
       "      <td>0.879913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.143300</td>\n",
       "      <td>0.286438</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.890952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.241953</td>\n",
       "      <td>0.889542</td>\n",
       "      <td>0.887487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.399037</td>\n",
       "      <td>0.900118</td>\n",
       "      <td>0.897002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.378772</td>\n",
       "      <td>0.902468</td>\n",
       "      <td>0.900989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.882491</td>\n",
       "      <td>0.882068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.330804</td>\n",
       "      <td>0.904818</td>\n",
       "      <td>0.902887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.421129</td>\n",
       "      <td>0.895417</td>\n",
       "      <td>0.890744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.411227</td>\n",
       "      <td>0.902468</td>\n",
       "      <td>0.901980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.345459</td>\n",
       "      <td>0.908343</td>\n",
       "      <td>0.905831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.362042</td>\n",
       "      <td>0.908343</td>\n",
       "      <td>0.906638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.360563</td>\n",
       "      <td>0.914219</td>\n",
       "      <td>0.912358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.361880</td>\n",
       "      <td>0.914219</td>\n",
       "      <td>0.912478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.401112</td>\n",
       "      <td>0.907168</td>\n",
       "      <td>0.904353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.401243</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.911851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.396301</td>\n",
       "      <td>0.920094</td>\n",
       "      <td>0.918274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.397522</td>\n",
       "      <td>0.920094</td>\n",
       "      <td>0.918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.401370</td>\n",
       "      <td>0.915394</td>\n",
       "      <td>0.914086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.403330</td>\n",
       "      <td>0.914219</td>\n",
       "      <td>0.912918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-da, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.639600</td>\n",
       "      <td>0.519764</td>\n",
       "      <td>0.733255</td>\n",
       "      <td>0.693047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>0.442940</td>\n",
       "      <td>0.802585</td>\n",
       "      <td>0.802487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.381600</td>\n",
       "      <td>0.335722</td>\n",
       "      <td>0.850764</td>\n",
       "      <td>0.848840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.293777</td>\n",
       "      <td>0.867215</td>\n",
       "      <td>0.865280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>0.295434</td>\n",
       "      <td>0.862515</td>\n",
       "      <td>0.859332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.355712</td>\n",
       "      <td>0.861340</td>\n",
       "      <td>0.855505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.333219</td>\n",
       "      <td>0.863690</td>\n",
       "      <td>0.856136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.248706</td>\n",
       "      <td>0.893067</td>\n",
       "      <td>0.890592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.276222</td>\n",
       "      <td>0.881316</td>\n",
       "      <td>0.879913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.143300</td>\n",
       "      <td>0.286438</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.890952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.241953</td>\n",
       "      <td>0.889542</td>\n",
       "      <td>0.887487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.399037</td>\n",
       "      <td>0.900118</td>\n",
       "      <td>0.897002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.378772</td>\n",
       "      <td>0.902468</td>\n",
       "      <td>0.900989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.882491</td>\n",
       "      <td>0.882068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.330804</td>\n",
       "      <td>0.904818</td>\n",
       "      <td>0.902887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.421129</td>\n",
       "      <td>0.895417</td>\n",
       "      <td>0.890744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.411227</td>\n",
       "      <td>0.902468</td>\n",
       "      <td>0.901980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.345459</td>\n",
       "      <td>0.908343</td>\n",
       "      <td>0.905831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.362042</td>\n",
       "      <td>0.908343</td>\n",
       "      <td>0.906638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.360563</td>\n",
       "      <td>0.914219</td>\n",
       "      <td>0.912358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.361880</td>\n",
       "      <td>0.914219</td>\n",
       "      <td>0.912478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.401112</td>\n",
       "      <td>0.907168</td>\n",
       "      <td>0.904353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.401243</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.911851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.396301</td>\n",
       "      <td>0.920094</td>\n",
       "      <td>0.918274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.397522</td>\n",
       "      <td>0.920094</td>\n",
       "      <td>0.918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.401370</td>\n",
       "      <td>0.915394</td>\n",
       "      <td>0.914086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.403330</td>\n",
       "      <td>0.914219</td>\n",
       "      <td>0.912918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>0.411191</td>\n",
       "      <td>0.804935</td>\n",
       "      <td>0.802035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.293050</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.868517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.243121</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.888473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.265900</td>\n",
       "      <td>0.203698</td>\n",
       "      <td>0.916569</td>\n",
       "      <td>0.914638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.207994</td>\n",
       "      <td>0.903643</td>\n",
       "      <td>0.900510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>0.239292</td>\n",
       "      <td>0.916569</td>\n",
       "      <td>0.914448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.207902</td>\n",
       "      <td>0.922444</td>\n",
       "      <td>0.921151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.175805</td>\n",
       "      <td>0.924794</td>\n",
       "      <td>0.923586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.176708</td>\n",
       "      <td>0.931845</td>\n",
       "      <td>0.930910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.194530</td>\n",
       "      <td>0.930670</td>\n",
       "      <td>0.929659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.195685</td>\n",
       "      <td>0.931845</td>\n",
       "      <td>0.930750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.231597</td>\n",
       "      <td>0.925969</td>\n",
       "      <td>0.923661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.278075</td>\n",
       "      <td>0.924794</td>\n",
       "      <td>0.923804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.306183</td>\n",
       "      <td>0.928320</td>\n",
       "      <td>0.927545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.280304</td>\n",
       "      <td>0.934195</td>\n",
       "      <td>0.932283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.333404</td>\n",
       "      <td>0.933020</td>\n",
       "      <td>0.932361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.260987</td>\n",
       "      <td>0.938895</td>\n",
       "      <td>0.937412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.291634</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.316219</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.939362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.250313</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.944831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.254542</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.270530</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.275467</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.944831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.281290</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.297153</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.945142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.299275</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>0.411191</td>\n",
       "      <td>0.804935</td>\n",
       "      <td>0.802035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.293050</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.868517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.243121</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.888473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.265900</td>\n",
       "      <td>0.203698</td>\n",
       "      <td>0.916569</td>\n",
       "      <td>0.914638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.207994</td>\n",
       "      <td>0.903643</td>\n",
       "      <td>0.900510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>0.239292</td>\n",
       "      <td>0.916569</td>\n",
       "      <td>0.914448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.207902</td>\n",
       "      <td>0.922444</td>\n",
       "      <td>0.921151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.175805</td>\n",
       "      <td>0.924794</td>\n",
       "      <td>0.923586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.176708</td>\n",
       "      <td>0.931845</td>\n",
       "      <td>0.930910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.194530</td>\n",
       "      <td>0.930670</td>\n",
       "      <td>0.929659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.195685</td>\n",
       "      <td>0.931845</td>\n",
       "      <td>0.930750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.231597</td>\n",
       "      <td>0.925969</td>\n",
       "      <td>0.923661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.278075</td>\n",
       "      <td>0.924794</td>\n",
       "      <td>0.923804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.306183</td>\n",
       "      <td>0.928320</td>\n",
       "      <td>0.927545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.280304</td>\n",
       "      <td>0.934195</td>\n",
       "      <td>0.932283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.333404</td>\n",
       "      <td>0.933020</td>\n",
       "      <td>0.932361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.260987</td>\n",
       "      <td>0.938895</td>\n",
       "      <td>0.937412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.291634</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.316219</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.939362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.250313</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.944831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.254542</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.270530</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.275467</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.944831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.281290</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.297153</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.945142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.299275</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1436ff50d1045d9a58d602e09946fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>0.411191</td>\n",
       "      <td>0.804935</td>\n",
       "      <td>0.802035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.293050</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.868517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.243121</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.888473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.265900</td>\n",
       "      <td>0.203698</td>\n",
       "      <td>0.916569</td>\n",
       "      <td>0.914638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.207994</td>\n",
       "      <td>0.903643</td>\n",
       "      <td>0.900510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>0.239292</td>\n",
       "      <td>0.916569</td>\n",
       "      <td>0.914448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.207902</td>\n",
       "      <td>0.922444</td>\n",
       "      <td>0.921151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.175805</td>\n",
       "      <td>0.924794</td>\n",
       "      <td>0.923586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.176708</td>\n",
       "      <td>0.931845</td>\n",
       "      <td>0.930910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.194530</td>\n",
       "      <td>0.930670</td>\n",
       "      <td>0.929659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.195685</td>\n",
       "      <td>0.931845</td>\n",
       "      <td>0.930750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.231597</td>\n",
       "      <td>0.925969</td>\n",
       "      <td>0.923661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.278075</td>\n",
       "      <td>0.924794</td>\n",
       "      <td>0.923804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.306183</td>\n",
       "      <td>0.928320</td>\n",
       "      <td>0.927545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.280304</td>\n",
       "      <td>0.934195</td>\n",
       "      <td>0.932283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.333404</td>\n",
       "      <td>0.933020</td>\n",
       "      <td>0.932361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.260987</td>\n",
       "      <td>0.938895</td>\n",
       "      <td>0.937412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.291634</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.316219</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.939362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.250313</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.944831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.254542</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.270530</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.275467</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.944831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.943596</td>\n",
       "      <td>0.942352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.281290</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.297153</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.945142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.299275</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.943998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reemalyami/AraRoBERTa-SA, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at reemalyami/AraRoBERTa-SA and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e6442fee7449378d174650966e2d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776d9448d8b9461fa729b85165bad5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.747356</td>\n",
       "      <td>0.745216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.472700</td>\n",
       "      <td>0.501752</td>\n",
       "      <td>0.768508</td>\n",
       "      <td>0.768462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.449700</td>\n",
       "      <td>0.365799</td>\n",
       "      <td>0.811986</td>\n",
       "      <td>0.806523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.381835</td>\n",
       "      <td>0.821387</td>\n",
       "      <td>0.820582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>0.339965</td>\n",
       "      <td>0.843713</td>\n",
       "      <td>0.841699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.268200</td>\n",
       "      <td>0.356351</td>\n",
       "      <td>0.846063</td>\n",
       "      <td>0.845132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.385520</td>\n",
       "      <td>0.855464</td>\n",
       "      <td>0.853679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.350287</td>\n",
       "      <td>0.854289</td>\n",
       "      <td>0.850527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.261600</td>\n",
       "      <td>0.339740</td>\n",
       "      <td>0.841363</td>\n",
       "      <td>0.840722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.316132</td>\n",
       "      <td>0.861340</td>\n",
       "      <td>0.858851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.338173</td>\n",
       "      <td>0.874266</td>\n",
       "      <td>0.869292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.418547</td>\n",
       "      <td>0.878966</td>\n",
       "      <td>0.874415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.464479</td>\n",
       "      <td>0.860165</td>\n",
       "      <td>0.859640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.388849</td>\n",
       "      <td>0.871915</td>\n",
       "      <td>0.867808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.348691</td>\n",
       "      <td>0.873090</td>\n",
       "      <td>0.870813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.342658</td>\n",
       "      <td>0.873090</td>\n",
       "      <td>0.870894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.401576</td>\n",
       "      <td>0.878966</td>\n",
       "      <td>0.878277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.468497</td>\n",
       "      <td>0.877791</td>\n",
       "      <td>0.873597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.472537</td>\n",
       "      <td>0.877791</td>\n",
       "      <td>0.875828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.471069</td>\n",
       "      <td>0.881316</td>\n",
       "      <td>0.880148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.473649</td>\n",
       "      <td>0.875441</td>\n",
       "      <td>0.874063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.492319</td>\n",
       "      <td>0.868390</td>\n",
       "      <td>0.865196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.524732</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.868517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.523955</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.866043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.534427</td>\n",
       "      <td>0.873090</td>\n",
       "      <td>0.871687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.539070</td>\n",
       "      <td>0.874266</td>\n",
       "      <td>0.872907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.538044</td>\n",
       "      <td>0.874266</td>\n",
       "      <td>0.872907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reemalyami/AraRoBERTa-SA, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at reemalyami/AraRoBERTa-SA and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4effa107ce49238aa3c0b869b3ef6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ce977199ab40d7acd6644f7e12c239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.747356</td>\n",
       "      <td>0.745216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.472700</td>\n",
       "      <td>0.501752</td>\n",
       "      <td>0.768508</td>\n",
       "      <td>0.768462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.449700</td>\n",
       "      <td>0.365799</td>\n",
       "      <td>0.811986</td>\n",
       "      <td>0.806523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.381835</td>\n",
       "      <td>0.821387</td>\n",
       "      <td>0.820582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>0.339965</td>\n",
       "      <td>0.843713</td>\n",
       "      <td>0.841699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.268200</td>\n",
       "      <td>0.356351</td>\n",
       "      <td>0.846063</td>\n",
       "      <td>0.845132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.385520</td>\n",
       "      <td>0.855464</td>\n",
       "      <td>0.853679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.350287</td>\n",
       "      <td>0.854289</td>\n",
       "      <td>0.850527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.261600</td>\n",
       "      <td>0.339740</td>\n",
       "      <td>0.841363</td>\n",
       "      <td>0.840722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.316132</td>\n",
       "      <td>0.861340</td>\n",
       "      <td>0.858851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.338173</td>\n",
       "      <td>0.874266</td>\n",
       "      <td>0.869292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.418547</td>\n",
       "      <td>0.878966</td>\n",
       "      <td>0.874415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.464479</td>\n",
       "      <td>0.860165</td>\n",
       "      <td>0.859640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.388849</td>\n",
       "      <td>0.871915</td>\n",
       "      <td>0.867808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.348691</td>\n",
       "      <td>0.873090</td>\n",
       "      <td>0.870813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.342658</td>\n",
       "      <td>0.873090</td>\n",
       "      <td>0.870894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.401576</td>\n",
       "      <td>0.878966</td>\n",
       "      <td>0.878277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.468497</td>\n",
       "      <td>0.877791</td>\n",
       "      <td>0.873597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.472537</td>\n",
       "      <td>0.877791</td>\n",
       "      <td>0.875828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.471069</td>\n",
       "      <td>0.881316</td>\n",
       "      <td>0.880148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.473649</td>\n",
       "      <td>0.875441</td>\n",
       "      <td>0.874063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.492319</td>\n",
       "      <td>0.868390</td>\n",
       "      <td>0.865196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.524732</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.868517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.523955</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.866043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.534427</td>\n",
       "      <td>0.873090</td>\n",
       "      <td>0.871687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.539070</td>\n",
       "      <td>0.874266</td>\n",
       "      <td>0.872907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.538044</td>\n",
       "      <td>0.874266</td>\n",
       "      <td>0.872907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reemalyami/AraRoBERTa-SA, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at reemalyami/AraRoBERTa-SA and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbe7f8e547a4365a69da22ae0240847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7735c38fd3244e59b57c144286f0fe2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.747356</td>\n",
       "      <td>0.745216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.472700</td>\n",
       "      <td>0.501752</td>\n",
       "      <td>0.768508</td>\n",
       "      <td>0.768462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.449700</td>\n",
       "      <td>0.365799</td>\n",
       "      <td>0.811986</td>\n",
       "      <td>0.806523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.381835</td>\n",
       "      <td>0.821387</td>\n",
       "      <td>0.820582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>0.339965</td>\n",
       "      <td>0.843713</td>\n",
       "      <td>0.841699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.268200</td>\n",
       "      <td>0.356351</td>\n",
       "      <td>0.846063</td>\n",
       "      <td>0.845132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.385520</td>\n",
       "      <td>0.855464</td>\n",
       "      <td>0.853679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.350287</td>\n",
       "      <td>0.854289</td>\n",
       "      <td>0.850527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.261600</td>\n",
       "      <td>0.339740</td>\n",
       "      <td>0.841363</td>\n",
       "      <td>0.840722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.316132</td>\n",
       "      <td>0.861340</td>\n",
       "      <td>0.858851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.338173</td>\n",
       "      <td>0.874266</td>\n",
       "      <td>0.869292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.418547</td>\n",
       "      <td>0.878966</td>\n",
       "      <td>0.874415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.464479</td>\n",
       "      <td>0.860165</td>\n",
       "      <td>0.859640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.388849</td>\n",
       "      <td>0.871915</td>\n",
       "      <td>0.867808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.348691</td>\n",
       "      <td>0.873090</td>\n",
       "      <td>0.870813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.342658</td>\n",
       "      <td>0.873090</td>\n",
       "      <td>0.870894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.401576</td>\n",
       "      <td>0.878966</td>\n",
       "      <td>0.878277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.468497</td>\n",
       "      <td>0.877791</td>\n",
       "      <td>0.873597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.472537</td>\n",
       "      <td>0.877791</td>\n",
       "      <td>0.875828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.471069</td>\n",
       "      <td>0.881316</td>\n",
       "      <td>0.880148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.473649</td>\n",
       "      <td>0.875441</td>\n",
       "      <td>0.874063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.492319</td>\n",
       "      <td>0.868390</td>\n",
       "      <td>0.865196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.524732</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.868517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.523955</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.866043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.534427</td>\n",
       "      <td>0.873090</td>\n",
       "      <td>0.871687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.539070</td>\n",
       "      <td>0.874266</td>\n",
       "      <td>0.872907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.538044</td>\n",
       "      <td>0.874266</td>\n",
       "      <td>0.872907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAMeL-Lab/bert-base-arabic-camelbert-da</td>\n",
       "      <td>0.920094</td>\n",
       "      <td>0.918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aubmindlab/bert-base-arabertv02-twitter</td>\n",
       "      <td>0.950646</td>\n",
       "      <td>0.949728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qarib/bert-base-qarib</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.945142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reemalyami/AraRoBERTa-SA</td>\n",
       "      <td>0.881316</td>\n",
       "      <td>0.880148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Accuracy        F1\n",
       "0  CAMeL-Lab/bert-base-arabic-camelbert-da  0.920094  0.918500\n",
       "3  aubmindlab/bert-base-arabertv02-twitter  0.950646  0.949728\n",
       "5                    qarib/bert-base-qarib  0.945946  0.945142\n",
       "8                 reemalyami/AraRoBERTa-SA  0.881316  0.880148"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "log_file = 'SS2030_1.txt'\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "df = pd.read_csv('benchmarks2/SS2030/SS2030.csv', encoding='utf-8', engine='python') #, quotechar=\"'\"  , quoting=3\n",
    "display(df.columns)\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "display(df[:4])\n",
    "\n",
    "df = df[df['text'] != '']\n",
    "\n",
    "classes = set(df['Sentiment'].values)\n",
    "display(classes)\n",
    "\n",
    "\n",
    "df['label'] = df['Sentiment']\n",
    "\n",
    "df = df[['text', 'label']]\n",
    "\n",
    "\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "# display(len(df_test))\n",
    "\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "display(ds)\n",
    "\n",
    "# max_sequence_length = 128\n",
    "max_sequence_length = 128\n",
    "\n",
    "models = [ \n",
    "        'aubmindlab/bert-base-arabertv02-twitter',\n",
    "        'CAMeL-Lab/bert-base-arabic-camelbert-da',\n",
    "        'qarib/bert-base-qarib',\n",
    "        'reemalyami/AraRoBERTa-SA',    \n",
    "]\n",
    "\n",
    "for model_name in models:\n",
    "    for i in range(3):\n",
    "        print(f'{model_name}, try:{i}')\n",
    "              \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                              num_labels=classes_num).to('cuda')                                                 \n",
    "        dataset_train = ds['train']\n",
    "        dataset_validation = ds['test']                                                    \n",
    "        \n",
    "      \n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            return tokenizer(examples['text'], truncation=True, padding=\"max_length\",\n",
    "                            max_length=max_sequence_length, add_special_tokens=True)\n",
    "        \n",
    "        \n",
    "        dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "        dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "        \n",
    "       \n",
    "        \n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)    \n",
    "            acc = accuracy_score(labels, predictions)        \n",
    "            f1 = f1_score(labels, predictions, average='macro')   \n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{model_name},{acc},{f1}\\n')\n",
    "            return {'accuracy': acc, 'f1_score': f1}\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        epochs = 5\n",
    "        save_steps = 10000 #save checkpoint every 10000 steps\n",
    "        batch_size = 64\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = 'bert/',\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs = epochs,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            save_steps = save_steps,\n",
    "            save_total_limit = 1, #only save the last 5 checkpoints\n",
    "            fp16=True,\n",
    "            learning_rate = 5e-5,  # 5e-5 is the default\n",
    "            logging_steps = 10, #50_000\n",
    "            evaluation_strategy = 'steps',\n",
    "            # evaluate_during_training = True,\n",
    "            eval_steps = 10\n",
    "            \n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args = training_args,\n",
    "            # data_collator=data_collator,\n",
    "            train_dataset=dataset_train,\n",
    "            eval_dataset=dataset_validation,\n",
    "            compute_metrics = compute_metrics\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # trainer.train(resume_from_checkpoint=True)\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv('SS2030_results_1.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b7f13-c4fa-4355-9192-11d71fbab952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382f88d-15fb-48d8-8b29-f328f6817a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb4923-7e46-4c22-a4b7-0321fdc9c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offical results\n",
    "Model \tAccuracy \tF1\n",
    "0 \tCAMeL-Lab/bert-base-arabic-camelbert-da \t0.920094 \t0.918500\n",
    "3 \taubmindlab/bert-base-arabertv02-twitter \t0.950646 \t0.949728\n",
    "5 \tqarib/bert-base-qarib \t                    0.945946 \t0.945142\n",
    "8 \treemalyami/AraRoBERTa-SA \t                0.881316 \t0.880148"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

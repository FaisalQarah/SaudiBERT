{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Review', 'Size', 'Color', 'Price', 'Smell', 'Sleeve', 'Quality',\n",
       "       'Fabric', 'Style', 'Length', 'Image', 'transperancy', 'in general',\n",
       "       'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Price</th>\n",
       "      <th>Smell</th>\n",
       "      <th>Sleeve</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Fabric</th>\n",
       "      <th>Style</th>\n",
       "      <th>Length</th>\n",
       "      <th>Image</th>\n",
       "      <th>transperancy</th>\n",
       "      <th>in general</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قماشه خفيييييف ينفع لصيف وطولي ١٥٦ وطلع ع طولي</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ملائم: رووووووووووووووو ووووووووووعة ماشاءالله تبارك الله جميييييييييييييييييييييييييييييييييييييل جدددددددددددددددددا فنتاستتتتتتتتتتتتتتتتتتتتتتتتتتتتتك راااااااااااااااااااااااااااااااااااااااااااااااااااااااااااائع</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>القصه والفستان واللون حلو بس القماش مره لا😭😭</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>يابنات صدق خذوووه قسم بالله يحلليييي ويخليييك احلاهم 🫠❤️‍🔥❤️‍🔥❤️‍🔥❤️‍🔥❤️‍🔥</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                       Review   \n",
       "0                                                                                                                                                                              قماشه خفيييييف ينفع لصيف وطولي ١٥٦ وطلع ع طولي  \\\n",
       "1  ملائم: رووووووووووووووو ووووووووووعة ماشاءالله تبارك الله جميييييييييييييييييييييييييييييييييييييل جدددددددددددددددددا فنتاستتتتتتتتتتتتتتتتتتتتتتتتتتتتتك راااااااااااااااااااااااااااااااااااااااااااااااااااااااااااائع   \n",
       "2                                                                                                                                                                                القصه والفستان واللون حلو بس القماش مره لا😭😭   \n",
       "3                                                                                                                                                  يابنات صدق خذوووه قسم بالله يحلليييي ويخليييك احلاهم 🫠❤️‍🔥❤️‍🔥❤️‍🔥❤️‍🔥❤️‍🔥   \n",
       "\n",
       "  Size Color Price Smell Sleeve Quality Fabric Style Length Image   \n",
       "0                                            1                     \\\n",
       "1                                                                   \n",
       "2        1.0                                -1   1.0                \n",
       "3                                                                   \n",
       "\n",
       "  transperancy in general Unnamed: 13 Unnamed: 14 Unnamed: 15 Unnamed: 16  \n",
       "0                     1.0       681.0       318.0       141.0       459.0  \n",
       "1                     1.0                                                  \n",
       "2                    -1.0                                                  \n",
       "3                     1.0                                                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{-1.0, 0.0, 1.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Review', 'label', '__index_level_0__'],\n",
       "        num_rows: 1712\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Review', 'label', '__index_level_0__'],\n",
       "        num_rows: 428\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02-twitter, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.723400</td>\n",
       "      <td>0.448682</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.585082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.395200</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.589643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.363200</td>\n",
       "      <td>0.343049</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.595146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.280900</td>\n",
       "      <td>0.324388</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.597660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.344003</td>\n",
       "      <td>0.894860</td>\n",
       "      <td>0.600622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.354098</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.591668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.746029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.405159</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.696611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.385352</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.757585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.121400</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.766789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.408826</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.740714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.454664</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.727136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.456349</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.758588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.738183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.536531</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.642131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.542135</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.537354</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.767472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.549853</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.766966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.553743</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.766789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.556958</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.772278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.574255</td>\n",
       "      <td>0.894860</td>\n",
       "      <td>0.732023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.596647</td>\n",
       "      <td>0.908879</td>\n",
       "      <td>0.773886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.588814</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.767166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.593656</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.599165</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.599911</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02-twitter, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.723400</td>\n",
       "      <td>0.448682</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.585082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.395200</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.589643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.363200</td>\n",
       "      <td>0.343049</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.595146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.280900</td>\n",
       "      <td>0.324388</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.597660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.344003</td>\n",
       "      <td>0.894860</td>\n",
       "      <td>0.600622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.354098</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.591668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.746029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.405159</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.696611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.385352</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.757585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.121400</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.766789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.408826</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.740714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.454664</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.727136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.456349</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.758588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.738183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.536531</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.642131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.542135</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.537354</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.767472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.549853</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.766966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.553743</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.766789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.556958</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.772278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.574255</td>\n",
       "      <td>0.894860</td>\n",
       "      <td>0.732023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.596647</td>\n",
       "      <td>0.908879</td>\n",
       "      <td>0.773886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.588814</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.767166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.593656</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.599165</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.599911</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02-twitter, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.723400</td>\n",
       "      <td>0.448682</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.585082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.395200</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.589643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.363200</td>\n",
       "      <td>0.343049</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.595146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.280900</td>\n",
       "      <td>0.324388</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.597660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.344003</td>\n",
       "      <td>0.894860</td>\n",
       "      <td>0.600622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.354098</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.591668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.746029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.405159</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.696611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.385352</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.757585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.121400</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.766789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.408826</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.740714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.454664</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.727136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.456349</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.758588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.738183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.536531</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.642131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.542135</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.537354</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.767472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.549853</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.766966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.553743</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.766789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.556958</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.772278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.574255</td>\n",
       "      <td>0.894860</td>\n",
       "      <td>0.732023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.596647</td>\n",
       "      <td>0.908879</td>\n",
       "      <td>0.773886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.588814</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.767166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.593656</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.599165</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.599911</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.770356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-da, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.836900</td>\n",
       "      <td>0.564754</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>0.539719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>0.430806</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.565136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.432200</td>\n",
       "      <td>0.417387</td>\n",
       "      <td>0.845794</td>\n",
       "      <td>0.568864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.374600</td>\n",
       "      <td>0.422779</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.570722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.314200</td>\n",
       "      <td>0.378103</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.589867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.392780</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.581624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.244300</td>\n",
       "      <td>0.414743</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.576247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.400666</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.627884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>0.479664</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.694850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>0.480241</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.703206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>0.462925</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.736898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.507790</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.724342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.585220</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.703822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.563457</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.747396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.570442</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.746790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.606213</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.743246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.636991</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.742941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.651714</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.743145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.648603</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.742606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.665876</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.738598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.687539</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.742851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.671350</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.748486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.687493</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.751494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.704434</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.746126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.698106</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.747921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.699986</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.749710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.699547</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.748302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-da, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.836900</td>\n",
       "      <td>0.564754</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>0.539719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>0.430806</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.565136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.432200</td>\n",
       "      <td>0.417387</td>\n",
       "      <td>0.845794</td>\n",
       "      <td>0.568864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.374600</td>\n",
       "      <td>0.422779</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.570722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.314200</td>\n",
       "      <td>0.378103</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.589867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.392780</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.581624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.244300</td>\n",
       "      <td>0.414743</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.576247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.400666</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.627884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>0.479664</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.694850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>0.480241</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.703206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>0.462925</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.736898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.507790</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.724342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.585220</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.703822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.563457</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.747396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.570442</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.746790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.606213</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.743246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.636991</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.742941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.651714</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.743145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.648603</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.742606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.665876</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.738598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.687539</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.742851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.671350</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.748486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.687493</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.751494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.704434</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.746126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.698106</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.747921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.699986</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.749710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.699547</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.748302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-da, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.836900</td>\n",
       "      <td>0.564754</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>0.539719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>0.430806</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.565136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.432200</td>\n",
       "      <td>0.417387</td>\n",
       "      <td>0.845794</td>\n",
       "      <td>0.568864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.374600</td>\n",
       "      <td>0.422779</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.570722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.314200</td>\n",
       "      <td>0.378103</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.589867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.392780</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.581624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.244300</td>\n",
       "      <td>0.414743</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.576247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.400666</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.627884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>0.479664</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.694850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>0.480241</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.703206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>0.462925</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.736898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.507790</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.724342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.585220</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.703822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.563457</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.747396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.570442</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.746790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.606213</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.743246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.636991</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.742941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.651714</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.743145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.648603</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.742606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.665876</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.738598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.687539</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.742851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.671350</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.748486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.687493</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.751494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.704434</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.746126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.698106</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.747921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.699986</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.749710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.699547</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.748302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.493540</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.548099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.479200</td>\n",
       "      <td>0.433498</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.577135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.360901</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.599720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.326600</td>\n",
       "      <td>0.337057</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.596760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.341293</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.601843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.387060</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.591931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.390651</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.702849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.369491</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.754136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.496983</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.701266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>0.437630</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.759116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.517685</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.742106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.527081</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.739728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.505767</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.791048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.527783</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.737398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.520279</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.796104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.581730</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.793488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.600420</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.791906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.616785</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.793586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.613885</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.792092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.624246</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.792092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.629635</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.804997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.645975</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.803413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.658748</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.793107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.663693</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.793300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.660366</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.791717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.663195</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.791717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.662339</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.791717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.493540</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.548099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.479200</td>\n",
       "      <td>0.433498</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.577135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.360901</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.599720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.326600</td>\n",
       "      <td>0.337057</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.596760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.341293</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.601843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.387060</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.591931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.390651</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.702849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.369491</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.754136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.496983</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.701266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>0.437630</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.759116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.517685</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.742106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.527081</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.739728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.505767</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.791048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.527783</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.737398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.520279</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.796104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.581730</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.793488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.600420</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.791906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.616785</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.793586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.613885</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.792092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.624246</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.792092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.629635</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.804997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.645975</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.803413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.658748</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.793107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.663693</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.793300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.660366</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.791717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.663195</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.791717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.662339</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.791717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.493540</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.548099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.479200</td>\n",
       "      <td>0.433498</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.577135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.360901</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.599720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.326600</td>\n",
       "      <td>0.337057</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.596760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.341293</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.601843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.387060</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.591931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.390651</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.702849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.369491</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.754136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.496983</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.701266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>0.437630</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.759116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.517685</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.742106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.527081</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.739728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.505767</td>\n",
       "      <td>0.885514</td>\n",
       "      <td>0.791048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.527783</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.737398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>0.520279</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.796104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.581730</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.793488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.600420</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.791906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.616785</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.793586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.613885</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.792092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.624246</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.792092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.629635</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.804997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.645975</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.803413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.658748</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.793107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.663693</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.793300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.660366</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.791717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.663195</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.791717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.662339</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.791717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reemalyami/AraRoBERTa-SA, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at reemalyami/AraRoBERTa-SA and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.804700</td>\n",
       "      <td>0.676994</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.505209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>0.497851</td>\n",
       "      <td>0.806075</td>\n",
       "      <td>0.539476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.501100</td>\n",
       "      <td>0.447941</td>\n",
       "      <td>0.838785</td>\n",
       "      <td>0.561113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.420200</td>\n",
       "      <td>0.437689</td>\n",
       "      <td>0.843458</td>\n",
       "      <td>0.564407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.351900</td>\n",
       "      <td>0.418061</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.576735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.511895</td>\n",
       "      <td>0.801402</td>\n",
       "      <td>0.540408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>0.442954</td>\n",
       "      <td>0.845794</td>\n",
       "      <td>0.567984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>0.630209</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.529092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.434407</td>\n",
       "      <td>0.843458</td>\n",
       "      <td>0.563903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.456998</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.565046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.439887</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.584376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>0.476505</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.580837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.599984</td>\n",
       "      <td>0.852804</td>\n",
       "      <td>0.569345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.088400</td>\n",
       "      <td>0.531438</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.575945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.568333</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.576767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.617321</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.624993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.712887</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.670789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.672189</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.625886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.686330</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.612302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.670746</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.654245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.669513</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.582955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.685598</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.576317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.718695</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.680665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.730645</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.656372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.729386</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.668626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.737272</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.663545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.738861</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.664879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reemalyami/AraRoBERTa-SA, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at reemalyami/AraRoBERTa-SA and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.804700</td>\n",
       "      <td>0.676994</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.505209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>0.497851</td>\n",
       "      <td>0.806075</td>\n",
       "      <td>0.539476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.501100</td>\n",
       "      <td>0.447941</td>\n",
       "      <td>0.838785</td>\n",
       "      <td>0.561113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.420200</td>\n",
       "      <td>0.437689</td>\n",
       "      <td>0.843458</td>\n",
       "      <td>0.564407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.351900</td>\n",
       "      <td>0.418061</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.576735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.511895</td>\n",
       "      <td>0.801402</td>\n",
       "      <td>0.540408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>0.442954</td>\n",
       "      <td>0.845794</td>\n",
       "      <td>0.567984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>0.630209</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.529092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.434407</td>\n",
       "      <td>0.843458</td>\n",
       "      <td>0.563903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.456998</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.565046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.439887</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.584376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>0.476505</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.580837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.599984</td>\n",
       "      <td>0.852804</td>\n",
       "      <td>0.569345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.088400</td>\n",
       "      <td>0.531438</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.575945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.568333</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.576767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.617321</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.624993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.712887</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.670789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.672189</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.625886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.686330</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.612302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.670746</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.654245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.669513</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.582955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.685598</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.576317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.718695</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.680665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.730645</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.656372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.729386</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.668626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.737272</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.663545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.738861</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.664879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reemalyami/AraRoBERTa-SA, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at reemalyami/AraRoBERTa-SA and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.804700</td>\n",
       "      <td>0.676994</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.505209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>0.497851</td>\n",
       "      <td>0.806075</td>\n",
       "      <td>0.539476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.501100</td>\n",
       "      <td>0.447941</td>\n",
       "      <td>0.838785</td>\n",
       "      <td>0.561113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.420200</td>\n",
       "      <td>0.437689</td>\n",
       "      <td>0.843458</td>\n",
       "      <td>0.564407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.351900</td>\n",
       "      <td>0.418061</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.576735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.511895</td>\n",
       "      <td>0.801402</td>\n",
       "      <td>0.540408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>0.442954</td>\n",
       "      <td>0.845794</td>\n",
       "      <td>0.567984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>0.630209</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.529092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.434407</td>\n",
       "      <td>0.843458</td>\n",
       "      <td>0.563903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.456998</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.565046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.439887</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.584376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>0.476505</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.580837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.599984</td>\n",
       "      <td>0.852804</td>\n",
       "      <td>0.569345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.088400</td>\n",
       "      <td>0.531438</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.575945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.568333</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.576767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.617321</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.624993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.712887</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.670789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.672189</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.625886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.686330</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.612302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.670746</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.654245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.669513</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.582955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.685598</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.576317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.718695</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.680665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.730645</td>\n",
       "      <td>0.855140</td>\n",
       "      <td>0.656372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.729386</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.668626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.737272</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.663545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.738861</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.664879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAMeL-Lab/bert-base-arabic-camelbert-da</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.751494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aubmindlab/bert-base-arabertv02-twitter</td>\n",
       "      <td>0.908879</td>\n",
       "      <td>0.773886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qarib/bert-base-qarib</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.804997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>reemalyami/AraRoBERTa-SA</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.680665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Accuracy        F1\n",
       "0  CAMeL-Lab/bert-base-arabic-camelbert-da  0.890187  0.751494\n",
       "3  aubmindlab/bert-base-arabertv02-twitter  0.908879  0.773886\n",
       "6                    qarib/bert-base-qarib  0.892523  0.804997\n",
       "9                 reemalyami/AraRoBERTa-SA  0.848131  0.680665"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "log_file = 'SaudiShopInsights_cloths_1.txt'\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('benchmarks2/SaudiShopInsights/ClothesDataset.csv', encoding='utf-8', \n",
    "                 engine='python', sep='\\t') #, quotechar=\"'\"  , quoting=3\n",
    "display(df.columns)\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "display(df[:4])\n",
    "\n",
    "df = df[df['Review'] != '']\n",
    "df = df[df['in general'] != '']\n",
    "classes = set(df['in general'].values)\n",
    "display(classes)\n",
    "\n",
    "display(len(df))\n",
    "\n",
    "\n",
    "display(len(df))\n",
    "\n",
    "df['in general'] = df['in general'].astype('category')\n",
    "df['label'] = df['in general'].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "df = df[['Review', 'label']]\n",
    "\n",
    "\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "# display(len(df_test))\n",
    "\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "display(ds)\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "models = [ \n",
    "        'aubmindlab/bert-base-arabertv02-twitter',\n",
    "        'CAMeL-Lab/bert-base-arabic-camelbert-da',\n",
    "        'qarib/bert-base-qarib',\n",
    "        'reemalyami/AraRoBERTa-SA',    \n",
    "]\n",
    "for model_name in models:\n",
    "    for i in range(3):\n",
    "        print(f'{model_name}, try:{i}')\n",
    "              \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                              num_labels=classes_num).to('cuda')                                                 \n",
    "        dataset_train = ds['train']\n",
    "        dataset_validation = ds['test']                                                    \n",
    "        \n",
    "      \n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            return tokenizer(examples['Review'], truncation=True, padding=\"max_length\",\n",
    "                            max_length=max_sequence_length, add_special_tokens=True)\n",
    "        \n",
    "        \n",
    "        dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "        dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "        \n",
    "       \n",
    "        \n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)    \n",
    "            acc = accuracy_score(labels, predictions)        \n",
    "            f1 = f1_score(labels, predictions, average='macro')   \n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{model_name},{acc},{f1}\\n')\n",
    "            return {'accuracy': acc, 'f1_score': f1}\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        epochs = 10\n",
    "        save_steps = 10000 #save checkpoint every 10000 steps\n",
    "        batch_size = 64\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = 'bert/',\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs = epochs,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            save_steps = save_steps,\n",
    "            save_total_limit = 1, #only save the last 5 checkpoints\n",
    "            fp16=True,\n",
    "            learning_rate = 5e-5,  # 5e-5 is the default\n",
    "            logging_steps = 10, #50_000\n",
    "            evaluation_strategy = 'steps',\n",
    "            # evaluate_during_training = True,\n",
    "            eval_steps = 10\n",
    "            \n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args = training_args,\n",
    "            # data_collator=data_collator,\n",
    "            train_dataset=dataset_train,\n",
    "            eval_dataset=dataset_validation,\n",
    "            compute_metrics = compute_metrics\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # trainer.train(resume_from_checkpoint=True)\n",
    "        trainer.train()\n",
    "     \n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv('SaudiShopInsights_cloths_results_1.csv')\n",
    "display(best_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b7f13-c4fa-4355-9192-11d71fbab952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb4923-7e46-4c22-a4b7-0321fdc9c707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

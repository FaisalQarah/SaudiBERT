{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 04:56:09.000104: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-03 04:56:09.024551: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-03 04:56:09.380752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Review', 'Size', 'Color', 'Price', 'Smell', 'Sleeve', 'Quality',\n",
       "       'Fabric', 'Style', 'Length', 'Image', 'transperancy', 'in general',\n",
       "       'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Price</th>\n",
       "      <th>Smell</th>\n",
       "      <th>Sleeve</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Fabric</th>\n",
       "      <th>Style</th>\n",
       "      <th>Length</th>\n",
       "      <th>Image</th>\n",
       "      <th>transperancy</th>\n",
       "      <th>in general</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ù‚Ù…Ø§Ø´Ù‡ Ø®ÙÙŠÙŠÙŠÙŠÙŠÙ ÙŠÙ†ÙØ¹ Ù„ØµÙŠÙ ÙˆØ·ÙˆÙ„ÙŠ Ù¡Ù¥Ù¦ ÙˆØ·Ù„Ø¹ Ø¹ Ø·ÙˆÙ„ÙŠ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ù…Ù„Ø§Ø¦Ù…: Ø±ÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆ ÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆØ¹Ø© Ù…Ø§Ø´Ø§Ø¡Ø§Ù„Ù„Ù‡ ØªØ¨Ø§Ø±Ùƒ Ø§Ù„Ù„Ù‡ Ø¬Ù…ÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙ„ Ø¬Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø§ ÙÙ†ØªØ§Ø³ØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªÙƒ Ø±Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø¦Ø¹</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ø§Ù„Ù‚ØµÙ‡ ÙˆØ§Ù„ÙØ³ØªØ§Ù† ÙˆØ§Ù„Ù„ÙˆÙ† Ø­Ù„Ùˆ Ø¨Ø³ Ø§Ù„Ù‚Ù…Ø§Ø´ Ù…Ø±Ù‡ Ù„Ø§ğŸ˜­ğŸ˜­</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ÙŠØ§Ø¨Ù†Ø§Øª ØµØ¯Ù‚ Ø®Ø°ÙˆÙˆÙˆÙ‡ Ù‚Ø³Ù… Ø¨Ø§Ù„Ù„Ù‡ ÙŠØ­Ù„Ù„ÙŠÙŠÙŠÙŠ ÙˆÙŠØ®Ù„ÙŠÙŠÙŠÙƒ Ø§Ø­Ù„Ø§Ù‡Ù… ğŸ« â¤ï¸â€ğŸ”¥â¤ï¸â€ğŸ”¥â¤ï¸â€ğŸ”¥â¤ï¸â€ğŸ”¥â¤ï¸â€ğŸ”¥</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                       Review   \n",
       "0                                                                                                                                                                              Ù‚Ù…Ø§Ø´Ù‡ Ø®ÙÙŠÙŠÙŠÙŠÙŠÙ ÙŠÙ†ÙØ¹ Ù„ØµÙŠÙ ÙˆØ·ÙˆÙ„ÙŠ Ù¡Ù¥Ù¦ ÙˆØ·Ù„Ø¹ Ø¹ Ø·ÙˆÙ„ÙŠ  \\\n",
       "1  Ù…Ù„Ø§Ø¦Ù…: Ø±ÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆ ÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆØ¹Ø© Ù…Ø§Ø´Ø§Ø¡Ø§Ù„Ù„Ù‡ ØªØ¨Ø§Ø±Ùƒ Ø§Ù„Ù„Ù‡ Ø¬Ù…ÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙŠÙ„ Ø¬Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø¯Ø§ ÙÙ†ØªØ§Ø³ØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªØªÙƒ Ø±Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø¦Ø¹   \n",
       "2                                                                                                                                                                                Ø§Ù„Ù‚ØµÙ‡ ÙˆØ§Ù„ÙØ³ØªØ§Ù† ÙˆØ§Ù„Ù„ÙˆÙ† Ø­Ù„Ùˆ Ø¨Ø³ Ø§Ù„Ù‚Ù…Ø§Ø´ Ù…Ø±Ù‡ Ù„Ø§ğŸ˜­ğŸ˜­   \n",
       "3                                                                                                                                                  ÙŠØ§Ø¨Ù†Ø§Øª ØµØ¯Ù‚ Ø®Ø°ÙˆÙˆÙˆÙ‡ Ù‚Ø³Ù… Ø¨Ø§Ù„Ù„Ù‡ ÙŠØ­Ù„Ù„ÙŠÙŠÙŠÙŠ ÙˆÙŠØ®Ù„ÙŠÙŠÙŠÙƒ Ø§Ø­Ù„Ø§Ù‡Ù… ğŸ« â¤ï¸â€ğŸ”¥â¤ï¸â€ğŸ”¥â¤ï¸â€ğŸ”¥â¤ï¸â€ğŸ”¥â¤ï¸â€ğŸ”¥   \n",
       "\n",
       "  Size Color Price Smell Sleeve Quality Fabric Style Length Image   \n",
       "0                                            1                     \\\n",
       "1                                                                   \n",
       "2        1.0                                -1   1.0                \n",
       "3                                                                   \n",
       "\n",
       "  transperancy in general Unnamed: 13 Unnamed: 14 Unnamed: 15 Unnamed: 16  \n",
       "0                     1.0       681.0       318.0       141.0       459.0  \n",
       "1                     1.0                                                  \n",
       "2                    -1.0                                                  \n",
       "3                     1.0                                                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{-1.0, 0.0, 1.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Review', 'label', '__index_level_0__'],\n",
       "        num_rows: 1712\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Review', 'label', '__index_level_0__'],\n",
       "        num_rows: 428\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.736100</td>\n",
       "      <td>0.502069</td>\n",
       "      <td>0.815421</td>\n",
       "      <td>0.540482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.527403</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.574656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.414500</td>\n",
       "      <td>0.387213</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.576388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.388440</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.580016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.364620</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.584761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.370102</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.638858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.476818</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.639921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.220100</td>\n",
       "      <td>0.393387</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.728058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.520247</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.808529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.105700</td>\n",
       "      <td>0.491960</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.820050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.442237</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.786721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.582254</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.788592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.506590</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.821858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.702415</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.788207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.558475</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.720046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.640102</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.763328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.621821</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.790120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.650303</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.769871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.664778</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.791931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.707866</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.789801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.726864</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.773521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.749080</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.763951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.729728</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.791749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.718659</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.761591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.733819</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.791749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.748111</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.794892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.748530</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.794892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.746500</td>\n",
       "      <td>0.527552</td>\n",
       "      <td>0.796729</td>\n",
       "      <td>0.526492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.344300</td>\n",
       "      <td>0.541493</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.576745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.430791</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.566663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.389931</td>\n",
       "      <td>0.852804</td>\n",
       "      <td>0.571540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.393229</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.674878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.204600</td>\n",
       "      <td>0.380935</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.679494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.459547</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.715107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>0.393775</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.770861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.430583</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.800416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.104100</td>\n",
       "      <td>0.539567</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.778008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.517341</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.770971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.499698</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.761500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.557455</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.788779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.636219</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.800680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>0.592135</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.787846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.666369</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.714844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.689365</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.757128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.669934</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.777773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.722662</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.749519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.754729</td>\n",
       "      <td>0.852804</td>\n",
       "      <td>0.737563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.734631</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.767082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.736538</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.775376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.713838</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.785790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.721485</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.774517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.753327</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.815180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.760466</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.802533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.758739</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.788534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faisalq/SaudiBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at faisalq/SaudiBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.746500</td>\n",
       "      <td>0.527552</td>\n",
       "      <td>0.796729</td>\n",
       "      <td>0.526492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.344300</td>\n",
       "      <td>0.541493</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.576745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.430791</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.566663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.389931</td>\n",
       "      <td>0.852804</td>\n",
       "      <td>0.571540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.393229</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.674878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.204600</td>\n",
       "      <td>0.380935</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.679494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.459547</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.715107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>0.393775</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.770861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.430583</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.800416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.104100</td>\n",
       "      <td>0.539567</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.778008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.517341</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.770971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.499698</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.761500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.557455</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.788779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.636219</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.800680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>0.592135</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.787846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.666369</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.714844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.689365</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.757128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.669934</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.777773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.722662</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.749519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.754729</td>\n",
       "      <td>0.852804</td>\n",
       "      <td>0.737563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.734631</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.767082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.736538</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.775376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.713838</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.785790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.721485</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.774517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.753327</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.815180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.760466</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.802533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.758739</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.788534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBC-NLP/MARBERT, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.844900</td>\n",
       "      <td>0.679624</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.342982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.535492</td>\n",
       "      <td>0.838785</td>\n",
       "      <td>0.560858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.564840</td>\n",
       "      <td>0.806075</td>\n",
       "      <td>0.532463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.432568</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.573054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.410462</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.580043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.302300</td>\n",
       "      <td>0.461258</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.567187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.367564</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.582513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.333992</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.585421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.484692</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.729533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.438933</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.722340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.426522</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.712192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.464309</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.718518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.120100</td>\n",
       "      <td>0.445394</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.736296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.469672</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.763893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.477735</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.697488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.595472</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.707083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.760288</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.739735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.594634</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.714248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.609833</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.756945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.611356</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.751211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.689119</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.681107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.687588</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.673802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.636020</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.712755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.640181</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.709145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.678445</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.739817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.681263</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.739817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.678833</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.739817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBC-NLP/MARBERT, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:28, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.844900</td>\n",
       "      <td>0.679624</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.342982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.535492</td>\n",
       "      <td>0.838785</td>\n",
       "      <td>0.560858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.564840</td>\n",
       "      <td>0.806075</td>\n",
       "      <td>0.532463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.432568</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.573054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.410462</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.580043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.302300</td>\n",
       "      <td>0.461258</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.567187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.367564</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.582513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.333992</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.585421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.484692</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.729533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.438933</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.722340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.426522</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.712192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.464309</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.718518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.120100</td>\n",
       "      <td>0.445394</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.736296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.469672</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.763893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.477735</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.697488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.595472</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.707083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.760288</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.739735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.594634</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.714248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.609833</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.756945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.611356</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.751211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.689119</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.681107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.687588</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.673802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.636020</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.712755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.640181</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.709145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.678445</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.739817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.681263</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.739817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.678833</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.739817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBC-NLP/MARBERT, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.844900</td>\n",
       "      <td>0.679624</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.342982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.535492</td>\n",
       "      <td>0.838785</td>\n",
       "      <td>0.560858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.564840</td>\n",
       "      <td>0.806075</td>\n",
       "      <td>0.532463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.432568</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.573054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.410462</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.580043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.302300</td>\n",
       "      <td>0.461258</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.567187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.367564</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.582513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.333992</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.585421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.484692</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.729533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.438933</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.722340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.426522</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.712192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.464309</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.718518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.120100</td>\n",
       "      <td>0.445394</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.736296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.469672</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.763893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.477735</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.697488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.595472</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.707083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.760288</td>\n",
       "      <td>0.848131</td>\n",
       "      <td>0.739735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.594634</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.714248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.609833</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.756945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.611356</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.751211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.689119</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.681107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.687588</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.673802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.636020</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.712755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.640181</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.709145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.678445</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.739817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.681263</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.739817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.678833</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.739817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBC-NLP/MARBERTv2, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.854700</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.612150</td>\n",
       "      <td>0.323716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.507100</td>\n",
       "      <td>0.518279</td>\n",
       "      <td>0.829439</td>\n",
       "      <td>0.552741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.471930</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.569167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.421108</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.573528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.352300</td>\n",
       "      <td>0.373599</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.592451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>0.388484</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.582480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>0.398916</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.580939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.364861</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.579202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.196900</td>\n",
       "      <td>0.359600</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.591597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.402893</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.584201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.386177</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.749441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.133200</td>\n",
       "      <td>0.467938</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.751063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.379719</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.805849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.473203</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.757728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.130100</td>\n",
       "      <td>0.384986</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.780127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.399225</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.783691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.544914</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.751286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.508866</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.751323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.464742</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.764543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.572907</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.765601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.514126</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.767213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.575677</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.742746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.517037</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.764473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.509561</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.766365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.593043</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.755304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.591250</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.758824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.596493</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.755304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBC-NLP/MARBERTv2, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.854700</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.612150</td>\n",
       "      <td>0.323716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.507100</td>\n",
       "      <td>0.518279</td>\n",
       "      <td>0.829439</td>\n",
       "      <td>0.552741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.471930</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.569167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.421108</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.573528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.352300</td>\n",
       "      <td>0.373599</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.592451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>0.388484</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.582480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>0.398916</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.580939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.364861</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.579202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.196900</td>\n",
       "      <td>0.359600</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.591597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.402893</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.584201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.386177</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.749441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.133200</td>\n",
       "      <td>0.467938</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.751063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.379719</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.805849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.473203</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.757728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.130100</td>\n",
       "      <td>0.384986</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.780127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.399225</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.783691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.544914</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.751286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.508866</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.751323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.464742</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.764543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.572907</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.765601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.514126</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.767213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.575677</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.742746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.517037</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.764473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.509561</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.766365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.593043</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.755304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.591250</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.758824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.596493</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.755304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBC-NLP/MARBERTv2, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee5b5d5495f4c64af6dd737383db70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070a2a8e94e046089b420d19ccc04553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.854700</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.612150</td>\n",
       "      <td>0.323716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.507100</td>\n",
       "      <td>0.518279</td>\n",
       "      <td>0.829439</td>\n",
       "      <td>0.552741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.471930</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.569167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.421108</td>\n",
       "      <td>0.857477</td>\n",
       "      <td>0.573528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.352300</td>\n",
       "      <td>0.373599</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.592451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>0.388484</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.582480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>0.398916</td>\n",
       "      <td>0.866822</td>\n",
       "      <td>0.580939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.364861</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.579202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.196900</td>\n",
       "      <td>0.359600</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.591597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.402893</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.584201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.386177</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.749441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.133200</td>\n",
       "      <td>0.467938</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.751063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.379719</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.805849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.473203</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.757728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.130100</td>\n",
       "      <td>0.384986</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.780127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.399225</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.783691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.544914</td>\n",
       "      <td>0.862150</td>\n",
       "      <td>0.751286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.508866</td>\n",
       "      <td>0.876168</td>\n",
       "      <td>0.751323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.464742</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.764543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.572907</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>0.765601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.514126</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.767213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.575677</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.742746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.517037</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.764473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.509561</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.766365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.593043</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.755304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.591250</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.758824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.596493</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.755304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UBC-NLP/MARBERT</td>\n",
       "      <td>0.880841</td>\n",
       "      <td>0.763893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UBC-NLP/MARBERTv2</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.805849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faisalq/SaudiBERT</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.821858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Accuracy        F1\n",
       "0    UBC-NLP/MARBERT  0.880841  0.763893\n",
       "3  UBC-NLP/MARBERTv2  0.899533  0.805849\n",
       "6  faisalq/SaudiBERT  0.883178  0.821858"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "log_file = 'SaudiShopInsights_cloths_2.txt'\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "df = pd.read_csv('benchmarks2/SaudiShopInsights/ClothesDataset.csv', encoding='utf-8', \n",
    "                 engine='python', sep='\\t') #, quotechar=\"'\"  , quoting=3\n",
    "display(df.columns)\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "display(df[:4])\n",
    "\n",
    "df = df[df['Review'] != '']\n",
    "df = df[df['in general'] != '']\n",
    "classes = set(df['in general'].values)\n",
    "display(classes)\n",
    "\n",
    "display(len(df))\n",
    "\n",
    "display(len(df))\n",
    "\n",
    "df['in general'] = df['in general'].astype('category')\n",
    "df['label'] = df['in general'].cat.codes\n",
    "\n",
    "df = df[['Review', 'label']]\n",
    "\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "display(ds)\n",
    "\n",
    "max_sequence_length = 128\n",
    "\n",
    "models = [ \n",
    "        'faisalq/SaudiBERT',\n",
    "        'UBC-NLP/MARBERT',\n",
    "        'UBC-NLP/MARBERTv2',  \n",
    "]\n",
    "\n",
    "for model_name in models:\n",
    "    for i in range(3):\n",
    "        print(f'{model_name}, try:{i}')\n",
    "              \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                              num_labels=classes_num).to('cuda')                                                 \n",
    "        dataset_train = ds['train']\n",
    "        dataset_validation = ds['test']                                                    \n",
    "        \n",
    "      \n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            return tokenizer(examples['Review'], truncation=True, padding=\"max_length\",\n",
    "                            max_length=max_sequence_length, add_special_tokens=True)\n",
    "        \n",
    "        \n",
    "        dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "        dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "        \n",
    "       \n",
    "        \n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)    \n",
    "            acc = accuracy_score(labels, predictions)        \n",
    "            f1 = f1_score(labels, predictions, average='macro')   \n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{model_name},{acc},{f1}\\n')\n",
    "            return {'accuracy': acc, 'f1_score': f1}\n",
    "\n",
    "        \n",
    "        epochs = 10\n",
    "        save_steps = 10000 #save checkpoint every 10000 steps\n",
    "        batch_size = 64\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = 'bert/',\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs = epochs,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            save_steps = save_steps,\n",
    "            save_total_limit = 1, #only save the last 5 checkpoints\n",
    "            fp16=True,\n",
    "            learning_rate = 5e-5,  # 5e-5 is the default\n",
    "            logging_steps = 10, #50_000\n",
    "            evaluation_strategy = 'steps',\n",
    "            # evaluate_during_training = True,\n",
    "            eval_steps = 10\n",
    "            \n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args = training_args,\n",
    "            # data_collator=data_collator,\n",
    "            train_dataset=dataset_train,\n",
    "            eval_dataset=dataset_validation,\n",
    "            compute_metrics = compute_metrics\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # trainer.train(resume_from_checkpoint=True)\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv('SaudiShopInsights_cloths_results_2.csv')\n",
    "display(best_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b7f13-c4fa-4355-9192-11d71fbab952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3f4f5-efda-4ffa-a775-45f127cf7bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

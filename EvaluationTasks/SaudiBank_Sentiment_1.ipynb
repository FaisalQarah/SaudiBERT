{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb60e6e-ebd4-4a2d-96f8-8b5f2c65d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 02:37:05.485820: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-27 02:37:05.513789: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-27 02:37:05.890071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Tweet', 'Bank', 'Tokens', 'Tokens without stop words',\n",
       "       'Annotator 1 & 3', 'Annotator 2 & 4', 'Final annotation'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Bank</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tokens without stop words</th>\n",
       "      <th>Annotator 1 &amp; 3</th>\n",
       "      <th>Annotator 2 &amp; 4</th>\n",
       "      <th>Final annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الله يقلعك من بنك دمر مستقبلنا الله حسبنا الله ونعم الوكيل فيك من بنك</td>\n",
       "      <td>SAIB</td>\n",
       "      <td>['الله', 'يقلعك', 'من', 'بنك', 'دمر', 'مستقبلنا', 'الله', 'حسبنا', 'الله', 'ونعم', 'الوكيل', 'فيك', 'من', 'بنك']</td>\n",
       "      <td>['الله', 'يقلعك', 'بنك', 'دمر', 'مستقبلنا', 'الله', 'حسبنا', 'الله', 'ونعم', 'الوكيل', 'فيك', 'بنك']</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>صار لي يومين بحاول اوصل لاي شخص من قبلكم يرد علي عجزت هل فعلا انتم بنك ولا شغل وهمي</td>\n",
       "      <td>SAIB</td>\n",
       "      <td>['صار', 'لي', 'يومين', 'بحاول', 'اوصل', 'لاي', 'شخص', 'من', 'قبلكم', 'يرد', 'علي', 'عجزت', 'هل', 'فعلا', 'انتم', 'بنك', 'ولا', 'شغل', 'وهمي']</td>\n",
       "      <td>['صار', 'لي', 'يومين', 'بحاول', 'اوصل', 'لاي', 'شخص', 'قبلكم', 'يرد', 'علي', 'عجزت', 'هل', 'فعلا', 'انتم', 'بنك', 'شغل', 'وهمي']</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>صادق كثير من الزملاء يشتكون منه الصراحه وبصراحه صرفت نظر عنه نهاءيا</td>\n",
       "      <td>SAIB</td>\n",
       "      <td>['صادق', 'كثير', 'من', 'الزملاء', 'يشتكون', 'منه', 'الصراحه', 'وبصراحه', 'صرفت', 'نظر', 'عنه', 'نهاءيا']</td>\n",
       "      <td>['صادق', 'كثير', 'الزملاء', 'يشتكون', 'منه', 'الصراحه', 'وبصراحه', 'صرفت', 'نظر', 'عنه', 'نهاءيا']</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ماقدرنا ناخذ بطاقه مدي وحسابي ذهبي وموظفين خدمه العملاء مو فاهمين وادور الفروع ومافي فايده علشان اطبع وادق عليكم بدون فايده للاسف تغيرتو للاسواء مو الافضل في خلل كبير عندكم</td>\n",
       "      <td>SAIB</td>\n",
       "      <td>['ماقدرنا', 'ناخذ', 'بطاقه', 'مدي', 'وحسابي', 'ذهبي', 'وموظفين', 'خدمه', 'العملاء', 'مو', 'فاهمين', 'وادور', 'الفروع', 'ومافي', 'فايده', 'علشان', 'اطبع', 'وادق', 'عليكم', 'بدون', 'فايده', 'للاسف', 'تغيرتو', 'للاسواء', 'مو', 'الافضل', 'في', 'خلل', 'كبير', 'عندكم']</td>\n",
       "      <td>['ماقدرنا', 'ناخذ', 'بطاقه', 'مدي', 'وحسابي', 'ذهبي', 'وموظفين', 'خدمه', 'العملاء', 'مو', 'فاهمين', 'وادور', 'الفروع', 'ومافي', 'فايده', 'علشان', 'اطبع', 'وادق', 'عليكم', 'بدون', 'فايده', 'للاسف', 'تغيرتو', 'للاسواء', 'مو', 'الافضل', 'خلل', 'كبير', 'عندكم']</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                          Tweet   \n",
       "0                                                                                                         الله يقلعك من بنك دمر مستقبلنا الله حسبنا الله ونعم الوكيل فيك من بنك  \\\n",
       "1                                                                                           صار لي يومين بحاول اوصل لاي شخص من قبلكم يرد علي عجزت هل فعلا انتم بنك ولا شغل وهمي   \n",
       "2                                                                                                           صادق كثير من الزملاء يشتكون منه الصراحه وبصراحه صرفت نظر عنه نهاءيا   \n",
       "3  ماقدرنا ناخذ بطاقه مدي وحسابي ذهبي وموظفين خدمه العملاء مو فاهمين وادور الفروع ومافي فايده علشان اطبع وادق عليكم بدون فايده للاسف تغيرتو للاسواء مو الافضل في خلل كبير عندكم   \n",
       "\n",
       "   Bank   \n",
       "0  SAIB  \\\n",
       "1  SAIB   \n",
       "2  SAIB   \n",
       "3  SAIB   \n",
       "\n",
       "                                                                                                                                                                                                                                                                    Tokens   \n",
       "0                                                                                                                                                         ['الله', 'يقلعك', 'من', 'بنك', 'دمر', 'مستقبلنا', 'الله', 'حسبنا', 'الله', 'ونعم', 'الوكيل', 'فيك', 'من', 'بنك']  \\\n",
       "1                                                                                                                            ['صار', 'لي', 'يومين', 'بحاول', 'اوصل', 'لاي', 'شخص', 'من', 'قبلكم', 'يرد', 'علي', 'عجزت', 'هل', 'فعلا', 'انتم', 'بنك', 'ولا', 'شغل', 'وهمي']   \n",
       "2                                                                                                                                                                 ['صادق', 'كثير', 'من', 'الزملاء', 'يشتكون', 'منه', 'الصراحه', 'وبصراحه', 'صرفت', 'نظر', 'عنه', 'نهاءيا']   \n",
       "3  ['ماقدرنا', 'ناخذ', 'بطاقه', 'مدي', 'وحسابي', 'ذهبي', 'وموظفين', 'خدمه', 'العملاء', 'مو', 'فاهمين', 'وادور', 'الفروع', 'ومافي', 'فايده', 'علشان', 'اطبع', 'وادق', 'عليكم', 'بدون', 'فايده', 'للاسف', 'تغيرتو', 'للاسواء', 'مو', 'الافضل', 'في', 'خلل', 'كبير', 'عندكم']   \n",
       "\n",
       "                                                                                                                                                                                                                                           Tokens without stop words   \n",
       "0                                                                                                                                                               ['الله', 'يقلعك', 'بنك', 'دمر', 'مستقبلنا', 'الله', 'حسبنا', 'الله', 'ونعم', 'الوكيل', 'فيك', 'بنك']  \\\n",
       "1                                                                                                                                   ['صار', 'لي', 'يومين', 'بحاول', 'اوصل', 'لاي', 'شخص', 'قبلكم', 'يرد', 'علي', 'عجزت', 'هل', 'فعلا', 'انتم', 'بنك', 'شغل', 'وهمي']   \n",
       "2                                                                                                                                                                 ['صادق', 'كثير', 'الزملاء', 'يشتكون', 'منه', 'الصراحه', 'وبصراحه', 'صرفت', 'نظر', 'عنه', 'نهاءيا']   \n",
       "3  ['ماقدرنا', 'ناخذ', 'بطاقه', 'مدي', 'وحسابي', 'ذهبي', 'وموظفين', 'خدمه', 'العملاء', 'مو', 'فاهمين', 'وادور', 'الفروع', 'ومافي', 'فايده', 'علشان', 'اطبع', 'وادق', 'عليكم', 'بدون', 'فايده', 'للاسف', 'تغيرتو', 'للاسواء', 'مو', 'الافضل', 'خلل', 'كبير', 'عندكم']   \n",
       "\n",
       "  Annotator 1 & 3 Annotator 2 & 4 Final annotation  \n",
       "0             NEG             NEG              NEG  \n",
       "1             NEG             NEG              NEG  \n",
       "2             NEG             NEG              NEG  \n",
       "3             NEG             NEG              NEG  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'NEG', 'NEU', 'POS'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12048"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 9638\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Tweet', 'label'],\n",
       "        num_rows: 2410\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02-twitter, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='755' max='755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [755/755 01:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>0.442381</td>\n",
       "      <td>0.850622</td>\n",
       "      <td>0.646837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.410780</td>\n",
       "      <td>0.850207</td>\n",
       "      <td>0.701898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.398898</td>\n",
       "      <td>0.851867</td>\n",
       "      <td>0.606523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>0.396408</td>\n",
       "      <td>0.850207</td>\n",
       "      <td>0.676965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>0.419790</td>\n",
       "      <td>0.853527</td>\n",
       "      <td>0.621790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.412810</td>\n",
       "      <td>0.858921</td>\n",
       "      <td>0.671080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.253300</td>\n",
       "      <td>0.430693</td>\n",
       "      <td>0.851037</td>\n",
       "      <td>0.667403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.280900</td>\n",
       "      <td>0.425169</td>\n",
       "      <td>0.853942</td>\n",
       "      <td>0.651285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>0.412797</td>\n",
       "      <td>0.856017</td>\n",
       "      <td>0.688698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.290100</td>\n",
       "      <td>0.420099</td>\n",
       "      <td>0.849793</td>\n",
       "      <td>0.687360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>0.693658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.493459</td>\n",
       "      <td>0.851037</td>\n",
       "      <td>0.680515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.493402</td>\n",
       "      <td>0.845643</td>\n",
       "      <td>0.695599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.478519</td>\n",
       "      <td>0.845228</td>\n",
       "      <td>0.685541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.480675</td>\n",
       "      <td>0.843154</td>\n",
       "      <td>0.701027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.543596</td>\n",
       "      <td>0.848548</td>\n",
       "      <td>0.700940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.578780</td>\n",
       "      <td>0.846473</td>\n",
       "      <td>0.704712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.087900</td>\n",
       "      <td>0.614293</td>\n",
       "      <td>0.832780</td>\n",
       "      <td>0.702789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.574230</td>\n",
       "      <td>0.834440</td>\n",
       "      <td>0.702638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.581150</td>\n",
       "      <td>0.832780</td>\n",
       "      <td>0.700608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.621426</td>\n",
       "      <td>0.837344</td>\n",
       "      <td>0.698709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.635775</td>\n",
       "      <td>0.830290</td>\n",
       "      <td>0.701840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.654151</td>\n",
       "      <td>0.845228</td>\n",
       "      <td>0.694312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.646338</td>\n",
       "      <td>0.836100</td>\n",
       "      <td>0.698250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.650931</td>\n",
       "      <td>0.838589</td>\n",
       "      <td>0.698648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02-twitter, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='755' max='755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [755/755 01:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.524100</td>\n",
       "      <td>0.443001</td>\n",
       "      <td>0.851037</td>\n",
       "      <td>0.645881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.400300</td>\n",
       "      <td>0.405383</td>\n",
       "      <td>0.840664</td>\n",
       "      <td>0.713684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.391397</td>\n",
       "      <td>0.848963</td>\n",
       "      <td>0.614106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.374800</td>\n",
       "      <td>0.396047</td>\n",
       "      <td>0.848963</td>\n",
       "      <td>0.695635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.416948</td>\n",
       "      <td>0.856846</td>\n",
       "      <td>0.627454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.288200</td>\n",
       "      <td>0.413855</td>\n",
       "      <td>0.856846</td>\n",
       "      <td>0.664862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.248400</td>\n",
       "      <td>0.430763</td>\n",
       "      <td>0.852697</td>\n",
       "      <td>0.679610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.441036</td>\n",
       "      <td>0.854772</td>\n",
       "      <td>0.673210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.408650</td>\n",
       "      <td>0.854357</td>\n",
       "      <td>0.683306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.415358</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.689040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.512578</td>\n",
       "      <td>0.839419</td>\n",
       "      <td>0.697056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.500372</td>\n",
       "      <td>0.851452</td>\n",
       "      <td>0.677534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.494004</td>\n",
       "      <td>0.844398</td>\n",
       "      <td>0.691953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.485387</td>\n",
       "      <td>0.842739</td>\n",
       "      <td>0.683777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.485138</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.698945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>0.563957</td>\n",
       "      <td>0.839419</td>\n",
       "      <td>0.688176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.581386</td>\n",
       "      <td>0.839834</td>\n",
       "      <td>0.692948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.614215</td>\n",
       "      <td>0.833610</td>\n",
       "      <td>0.697718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.598831</td>\n",
       "      <td>0.833610</td>\n",
       "      <td>0.700398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.593650</td>\n",
       "      <td>0.835270</td>\n",
       "      <td>0.695164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.626820</td>\n",
       "      <td>0.842739</td>\n",
       "      <td>0.690658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.647528</td>\n",
       "      <td>0.827801</td>\n",
       "      <td>0.692997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.669419</td>\n",
       "      <td>0.844813</td>\n",
       "      <td>0.689097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.662999</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.688965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.665638</td>\n",
       "      <td>0.839419</td>\n",
       "      <td>0.689412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02-twitter, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='755' max='755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [755/755 01:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.524100</td>\n",
       "      <td>0.443001</td>\n",
       "      <td>0.851037</td>\n",
       "      <td>0.645881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.400300</td>\n",
       "      <td>0.405383</td>\n",
       "      <td>0.840664</td>\n",
       "      <td>0.713684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.391397</td>\n",
       "      <td>0.848963</td>\n",
       "      <td>0.614106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.374800</td>\n",
       "      <td>0.396047</td>\n",
       "      <td>0.848963</td>\n",
       "      <td>0.695635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.416948</td>\n",
       "      <td>0.856846</td>\n",
       "      <td>0.627454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.288200</td>\n",
       "      <td>0.413855</td>\n",
       "      <td>0.856846</td>\n",
       "      <td>0.664862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.248400</td>\n",
       "      <td>0.430763</td>\n",
       "      <td>0.852697</td>\n",
       "      <td>0.679610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.441036</td>\n",
       "      <td>0.854772</td>\n",
       "      <td>0.673210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.408650</td>\n",
       "      <td>0.854357</td>\n",
       "      <td>0.683306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.415358</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.689040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.512578</td>\n",
       "      <td>0.839419</td>\n",
       "      <td>0.697056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.500372</td>\n",
       "      <td>0.851452</td>\n",
       "      <td>0.677534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.494004</td>\n",
       "      <td>0.844398</td>\n",
       "      <td>0.691953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.485387</td>\n",
       "      <td>0.842739</td>\n",
       "      <td>0.683777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.485138</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.698945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>0.563957</td>\n",
       "      <td>0.839419</td>\n",
       "      <td>0.688176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.581386</td>\n",
       "      <td>0.839834</td>\n",
       "      <td>0.692948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.614215</td>\n",
       "      <td>0.833610</td>\n",
       "      <td>0.697718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.598831</td>\n",
       "      <td>0.833610</td>\n",
       "      <td>0.700398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.593650</td>\n",
       "      <td>0.835270</td>\n",
       "      <td>0.695164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.626820</td>\n",
       "      <td>0.842739</td>\n",
       "      <td>0.690658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.647528</td>\n",
       "      <td>0.827801</td>\n",
       "      <td>0.692997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.669419</td>\n",
       "      <td>0.844813</td>\n",
       "      <td>0.689097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.662999</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.688965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.665638</td>\n",
       "      <td>0.839419</td>\n",
       "      <td>0.689412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-da, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='755' max='755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [755/755 01:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.456481</td>\n",
       "      <td>0.836100</td>\n",
       "      <td>0.566872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.473127</td>\n",
       "      <td>0.800415</td>\n",
       "      <td>0.689793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.438900</td>\n",
       "      <td>0.430545</td>\n",
       "      <td>0.851037</td>\n",
       "      <td>0.606295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.402500</td>\n",
       "      <td>0.420627</td>\n",
       "      <td>0.853527</td>\n",
       "      <td>0.621860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.443576</td>\n",
       "      <td>0.848133</td>\n",
       "      <td>0.591914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.299800</td>\n",
       "      <td>0.442571</td>\n",
       "      <td>0.849793</td>\n",
       "      <td>0.648128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.451037</td>\n",
       "      <td>0.850622</td>\n",
       "      <td>0.669090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>0.447846</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.650148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.426904</td>\n",
       "      <td>0.849793</td>\n",
       "      <td>0.662693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.267900</td>\n",
       "      <td>0.439950</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.689684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.555545</td>\n",
       "      <td>0.845643</td>\n",
       "      <td>0.701301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.521886</td>\n",
       "      <td>0.847303</td>\n",
       "      <td>0.695316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.574285</td>\n",
       "      <td>0.845228</td>\n",
       "      <td>0.680549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.134900</td>\n",
       "      <td>0.556573</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.690931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.501815</td>\n",
       "      <td>0.848133</td>\n",
       "      <td>0.694092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.658135</td>\n",
       "      <td>0.833195</td>\n",
       "      <td>0.705522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.689483</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.699499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.695488</td>\n",
       "      <td>0.834440</td>\n",
       "      <td>0.695656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.717879</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.693505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.720909</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.687277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.760489</td>\n",
       "      <td>0.840664</td>\n",
       "      <td>0.690830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.777649</td>\n",
       "      <td>0.837344</td>\n",
       "      <td>0.686588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.818553</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.679088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.830890</td>\n",
       "      <td>0.829876</td>\n",
       "      <td>0.682407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.824383</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.680009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-da, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='755' max='755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [755/755 01:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.456481</td>\n",
       "      <td>0.836100</td>\n",
       "      <td>0.566872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.473127</td>\n",
       "      <td>0.800415</td>\n",
       "      <td>0.689793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.438900</td>\n",
       "      <td>0.430545</td>\n",
       "      <td>0.851037</td>\n",
       "      <td>0.606295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.402500</td>\n",
       "      <td>0.420627</td>\n",
       "      <td>0.853527</td>\n",
       "      <td>0.621860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.443576</td>\n",
       "      <td>0.848133</td>\n",
       "      <td>0.591914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.299800</td>\n",
       "      <td>0.442571</td>\n",
       "      <td>0.849793</td>\n",
       "      <td>0.648128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.451037</td>\n",
       "      <td>0.850622</td>\n",
       "      <td>0.669090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>0.447846</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.650148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.426904</td>\n",
       "      <td>0.849793</td>\n",
       "      <td>0.662693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.267900</td>\n",
       "      <td>0.439950</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.689684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.555545</td>\n",
       "      <td>0.845643</td>\n",
       "      <td>0.701301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.521886</td>\n",
       "      <td>0.847303</td>\n",
       "      <td>0.695316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.574285</td>\n",
       "      <td>0.845228</td>\n",
       "      <td>0.680549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.134900</td>\n",
       "      <td>0.556573</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.690931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.501815</td>\n",
       "      <td>0.848133</td>\n",
       "      <td>0.694092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.658135</td>\n",
       "      <td>0.833195</td>\n",
       "      <td>0.705522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.689483</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.699499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.695488</td>\n",
       "      <td>0.834440</td>\n",
       "      <td>0.695656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.717879</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.693505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.720909</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.687277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.760489</td>\n",
       "      <td>0.840664</td>\n",
       "      <td>0.690830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.777649</td>\n",
       "      <td>0.837344</td>\n",
       "      <td>0.686588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.818553</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.679088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.830890</td>\n",
       "      <td>0.829876</td>\n",
       "      <td>0.682407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.824383</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.680009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMeL-Lab/bert-base-arabic-camelbert-da, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='755' max='755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [755/755 01:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.456481</td>\n",
       "      <td>0.836100</td>\n",
       "      <td>0.566872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.473127</td>\n",
       "      <td>0.800415</td>\n",
       "      <td>0.689793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.438900</td>\n",
       "      <td>0.430545</td>\n",
       "      <td>0.851037</td>\n",
       "      <td>0.606295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.402500</td>\n",
       "      <td>0.420627</td>\n",
       "      <td>0.853527</td>\n",
       "      <td>0.621860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.443576</td>\n",
       "      <td>0.848133</td>\n",
       "      <td>0.591914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.299800</td>\n",
       "      <td>0.442571</td>\n",
       "      <td>0.849793</td>\n",
       "      <td>0.648128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.451037</td>\n",
       "      <td>0.850622</td>\n",
       "      <td>0.669090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>0.447846</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.650148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.426904</td>\n",
       "      <td>0.849793</td>\n",
       "      <td>0.662693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.267900</td>\n",
       "      <td>0.439950</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.689684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.555545</td>\n",
       "      <td>0.845643</td>\n",
       "      <td>0.701301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.521886</td>\n",
       "      <td>0.847303</td>\n",
       "      <td>0.695316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.574285</td>\n",
       "      <td>0.845228</td>\n",
       "      <td>0.680549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.134900</td>\n",
       "      <td>0.556573</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.690931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.501815</td>\n",
       "      <td>0.848133</td>\n",
       "      <td>0.694092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.658135</td>\n",
       "      <td>0.833195</td>\n",
       "      <td>0.705522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.689483</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.699499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.695488</td>\n",
       "      <td>0.834440</td>\n",
       "      <td>0.695656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.717879</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.693505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.720909</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.687277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.760489</td>\n",
       "      <td>0.840664</td>\n",
       "      <td>0.690830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.777649</td>\n",
       "      <td>0.837344</td>\n",
       "      <td>0.686588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.818553</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.679088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.830890</td>\n",
       "      <td>0.829876</td>\n",
       "      <td>0.682407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.824383</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.680009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='755' max='755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [755/755 01:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.516100</td>\n",
       "      <td>0.444224</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.611889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.409800</td>\n",
       "      <td>0.421833</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.682283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.403500</td>\n",
       "      <td>0.406941</td>\n",
       "      <td>0.852282</td>\n",
       "      <td>0.633120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.414545</td>\n",
       "      <td>0.847718</td>\n",
       "      <td>0.654517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.399600</td>\n",
       "      <td>0.392916</td>\n",
       "      <td>0.857676</td>\n",
       "      <td>0.647017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.850207</td>\n",
       "      <td>0.678537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.454314</td>\n",
       "      <td>0.833195</td>\n",
       "      <td>0.652774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.459528</td>\n",
       "      <td>0.844813</td>\n",
       "      <td>0.663198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.421298</td>\n",
       "      <td>0.853942</td>\n",
       "      <td>0.682623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>0.437296</td>\n",
       "      <td>0.845643</td>\n",
       "      <td>0.693689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>0.574727</td>\n",
       "      <td>0.834855</td>\n",
       "      <td>0.692129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>0.572722</td>\n",
       "      <td>0.855187</td>\n",
       "      <td>0.677843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.531060</td>\n",
       "      <td>0.841079</td>\n",
       "      <td>0.700677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.509601</td>\n",
       "      <td>0.841079</td>\n",
       "      <td>0.699242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.569256</td>\n",
       "      <td>0.826971</td>\n",
       "      <td>0.692972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.632046</td>\n",
       "      <td>0.836515</td>\n",
       "      <td>0.704911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.680103</td>\n",
       "      <td>0.844813</td>\n",
       "      <td>0.690678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.721437</td>\n",
       "      <td>0.830290</td>\n",
       "      <td>0.698296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.714972</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.697772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.706153</td>\n",
       "      <td>0.834440</td>\n",
       "      <td>0.690917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.775916</td>\n",
       "      <td>0.838589</td>\n",
       "      <td>0.686360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.797152</td>\n",
       "      <td>0.836515</td>\n",
       "      <td>0.684011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.840139</td>\n",
       "      <td>0.833195</td>\n",
       "      <td>0.678702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.848428</td>\n",
       "      <td>0.836100</td>\n",
       "      <td>0.683034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.855306</td>\n",
       "      <td>0.829461</td>\n",
       "      <td>0.691750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='755' max='755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [755/755 01:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.516100</td>\n",
       "      <td>0.444224</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.611889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.409800</td>\n",
       "      <td>0.421833</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.682283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.403500</td>\n",
       "      <td>0.406941</td>\n",
       "      <td>0.852282</td>\n",
       "      <td>0.633120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.414545</td>\n",
       "      <td>0.847718</td>\n",
       "      <td>0.654517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.399600</td>\n",
       "      <td>0.392916</td>\n",
       "      <td>0.857676</td>\n",
       "      <td>0.647017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.850207</td>\n",
       "      <td>0.678537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.454314</td>\n",
       "      <td>0.833195</td>\n",
       "      <td>0.652774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.459528</td>\n",
       "      <td>0.844813</td>\n",
       "      <td>0.663198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.421298</td>\n",
       "      <td>0.853942</td>\n",
       "      <td>0.682623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>0.437296</td>\n",
       "      <td>0.845643</td>\n",
       "      <td>0.693689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>0.574727</td>\n",
       "      <td>0.834855</td>\n",
       "      <td>0.692129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>0.572722</td>\n",
       "      <td>0.855187</td>\n",
       "      <td>0.677843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.531060</td>\n",
       "      <td>0.841079</td>\n",
       "      <td>0.700677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.509601</td>\n",
       "      <td>0.841079</td>\n",
       "      <td>0.699242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.569256</td>\n",
       "      <td>0.826971</td>\n",
       "      <td>0.692972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.632046</td>\n",
       "      <td>0.836515</td>\n",
       "      <td>0.704911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.680103</td>\n",
       "      <td>0.844813</td>\n",
       "      <td>0.690678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.721437</td>\n",
       "      <td>0.830290</td>\n",
       "      <td>0.698296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.714972</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.697772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.706153</td>\n",
       "      <td>0.834440</td>\n",
       "      <td>0.690917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.775916</td>\n",
       "      <td>0.838589</td>\n",
       "      <td>0.686360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.797152</td>\n",
       "      <td>0.836515</td>\n",
       "      <td>0.684011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.840139</td>\n",
       "      <td>0.833195</td>\n",
       "      <td>0.678702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.848428</td>\n",
       "      <td>0.836100</td>\n",
       "      <td>0.683034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.855306</td>\n",
       "      <td>0.829461</td>\n",
       "      <td>0.691750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qarib/bert-base-qarib, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at qarib/bert-base-qarib and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa96f5bf0e14ca985f8bf753c24d72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='755' max='755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [755/755 01:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.516100</td>\n",
       "      <td>0.444224</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.611889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.409800</td>\n",
       "      <td>0.421833</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.682283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.403500</td>\n",
       "      <td>0.406941</td>\n",
       "      <td>0.852282</td>\n",
       "      <td>0.633120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.414545</td>\n",
       "      <td>0.847718</td>\n",
       "      <td>0.654517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.399600</td>\n",
       "      <td>0.392916</td>\n",
       "      <td>0.857676</td>\n",
       "      <td>0.647017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.850207</td>\n",
       "      <td>0.678537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.454314</td>\n",
       "      <td>0.833195</td>\n",
       "      <td>0.652774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.459528</td>\n",
       "      <td>0.844813</td>\n",
       "      <td>0.663198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.421298</td>\n",
       "      <td>0.853942</td>\n",
       "      <td>0.682623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>0.437296</td>\n",
       "      <td>0.845643</td>\n",
       "      <td>0.693689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>0.574727</td>\n",
       "      <td>0.834855</td>\n",
       "      <td>0.692129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>0.572722</td>\n",
       "      <td>0.855187</td>\n",
       "      <td>0.677843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.531060</td>\n",
       "      <td>0.841079</td>\n",
       "      <td>0.700677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.509601</td>\n",
       "      <td>0.841079</td>\n",
       "      <td>0.699242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.569256</td>\n",
       "      <td>0.826971</td>\n",
       "      <td>0.692972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.632046</td>\n",
       "      <td>0.836515</td>\n",
       "      <td>0.704911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.680103</td>\n",
       "      <td>0.844813</td>\n",
       "      <td>0.690678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.721437</td>\n",
       "      <td>0.830290</td>\n",
       "      <td>0.698296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.714972</td>\n",
       "      <td>0.843568</td>\n",
       "      <td>0.697772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.706153</td>\n",
       "      <td>0.834440</td>\n",
       "      <td>0.690917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.775916</td>\n",
       "      <td>0.838589</td>\n",
       "      <td>0.686360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.797152</td>\n",
       "      <td>0.836515</td>\n",
       "      <td>0.684011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.840139</td>\n",
       "      <td>0.833195</td>\n",
       "      <td>0.678702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.848428</td>\n",
       "      <td>0.836100</td>\n",
       "      <td>0.683034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.855306</td>\n",
       "      <td>0.829461</td>\n",
       "      <td>0.691750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reemalyami/AraRoBERTa-SA, try:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at reemalyami/AraRoBERTa-SA and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d92bb015e34a16bec9e9ed0c5ce951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e00c7aa43c4278af620a315ebef156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='755' max='755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [755/755 01:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>0.535883</td>\n",
       "      <td>0.818672</td>\n",
       "      <td>0.557784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>0.493007</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>0.666825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.437381</td>\n",
       "      <td>0.841079</td>\n",
       "      <td>0.578135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.444622</td>\n",
       "      <td>0.844813</td>\n",
       "      <td>0.642995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>0.445895</td>\n",
       "      <td>0.843154</td>\n",
       "      <td>0.603819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.342700</td>\n",
       "      <td>0.504401</td>\n",
       "      <td>0.846888</td>\n",
       "      <td>0.617561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>0.460739</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>0.669175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.476159</td>\n",
       "      <td>0.846058</td>\n",
       "      <td>0.594520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>0.435403</td>\n",
       "      <td>0.848548</td>\n",
       "      <td>0.629667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.470724</td>\n",
       "      <td>0.847303</td>\n",
       "      <td>0.644419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.541692</td>\n",
       "      <td>0.835270</td>\n",
       "      <td>0.683438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.542389</td>\n",
       "      <td>0.846888</td>\n",
       "      <td>0.679742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.534417</td>\n",
       "      <td>0.853527</td>\n",
       "      <td>0.674511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.507853</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>0.685063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.539344</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.685454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.608300</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>0.691839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.630235</td>\n",
       "      <td>0.841494</td>\n",
       "      <td>0.673192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>0.669115</td>\n",
       "      <td>0.836929</td>\n",
       "      <td>0.683059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.633469</td>\n",
       "      <td>0.836515</td>\n",
       "      <td>0.683572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.618775</td>\n",
       "      <td>0.841494</td>\n",
       "      <td>0.691103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.713872</td>\n",
       "      <td>0.843154</td>\n",
       "      <td>0.672907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.708801</td>\n",
       "      <td>0.832780</td>\n",
       "      <td>0.689776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.767915</td>\n",
       "      <td>0.843983</td>\n",
       "      <td>0.669951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.752052</td>\n",
       "      <td>0.837344</td>\n",
       "      <td>0.685506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.753515</td>\n",
       "      <td>0.835685</td>\n",
       "      <td>0.683190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reemalyami/AraRoBERTa-SA, try:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at reemalyami/AraRoBERTa-SA and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e967f7c83849e0bd44020f371afe85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9474c743805b4136a070a0bdc2903ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='755' max='755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [755/755 01:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>0.535883</td>\n",
       "      <td>0.818672</td>\n",
       "      <td>0.557784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>0.493007</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>0.666825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.437381</td>\n",
       "      <td>0.841079</td>\n",
       "      <td>0.578135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.444622</td>\n",
       "      <td>0.844813</td>\n",
       "      <td>0.642995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>0.445895</td>\n",
       "      <td>0.843154</td>\n",
       "      <td>0.603819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.342700</td>\n",
       "      <td>0.504401</td>\n",
       "      <td>0.846888</td>\n",
       "      <td>0.617561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>0.460739</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>0.669175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.476159</td>\n",
       "      <td>0.846058</td>\n",
       "      <td>0.594520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>0.435403</td>\n",
       "      <td>0.848548</td>\n",
       "      <td>0.629667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.470724</td>\n",
       "      <td>0.847303</td>\n",
       "      <td>0.644419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.541692</td>\n",
       "      <td>0.835270</td>\n",
       "      <td>0.683438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.542389</td>\n",
       "      <td>0.846888</td>\n",
       "      <td>0.679742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.534417</td>\n",
       "      <td>0.853527</td>\n",
       "      <td>0.674511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.507853</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>0.685063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.539344</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.685454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.608300</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>0.691839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.630235</td>\n",
       "      <td>0.841494</td>\n",
       "      <td>0.673192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>0.669115</td>\n",
       "      <td>0.836929</td>\n",
       "      <td>0.683059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.633469</td>\n",
       "      <td>0.836515</td>\n",
       "      <td>0.683572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.618775</td>\n",
       "      <td>0.841494</td>\n",
       "      <td>0.691103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.713872</td>\n",
       "      <td>0.843154</td>\n",
       "      <td>0.672907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.708801</td>\n",
       "      <td>0.832780</td>\n",
       "      <td>0.689776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.767915</td>\n",
       "      <td>0.843983</td>\n",
       "      <td>0.669951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.752052</td>\n",
       "      <td>0.837344</td>\n",
       "      <td>0.685506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.753515</td>\n",
       "      <td>0.835685</td>\n",
       "      <td>0.683190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reemalyami/AraRoBERTa-SA, try:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at reemalyami/AraRoBERTa-SA and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad92823e3354434580b64616deccdd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2370251d8a442ebdd94bfbfd14ce14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='755' max='755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [755/755 01:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>0.535883</td>\n",
       "      <td>0.818672</td>\n",
       "      <td>0.557784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>0.493007</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>0.666825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.437381</td>\n",
       "      <td>0.841079</td>\n",
       "      <td>0.578135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.444622</td>\n",
       "      <td>0.844813</td>\n",
       "      <td>0.642995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>0.445895</td>\n",
       "      <td>0.843154</td>\n",
       "      <td>0.603819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.342700</td>\n",
       "      <td>0.504401</td>\n",
       "      <td>0.846888</td>\n",
       "      <td>0.617561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>0.460739</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>0.669175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.476159</td>\n",
       "      <td>0.846058</td>\n",
       "      <td>0.594520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>0.435403</td>\n",
       "      <td>0.848548</td>\n",
       "      <td>0.629667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.470724</td>\n",
       "      <td>0.847303</td>\n",
       "      <td>0.644419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.541692</td>\n",
       "      <td>0.835270</td>\n",
       "      <td>0.683438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.542389</td>\n",
       "      <td>0.846888</td>\n",
       "      <td>0.679742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.534417</td>\n",
       "      <td>0.853527</td>\n",
       "      <td>0.674511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.507853</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>0.685063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.539344</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.685454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.608300</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>0.691839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.630235</td>\n",
       "      <td>0.841494</td>\n",
       "      <td>0.673192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>0.669115</td>\n",
       "      <td>0.836929</td>\n",
       "      <td>0.683059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.633469</td>\n",
       "      <td>0.836515</td>\n",
       "      <td>0.683572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.618775</td>\n",
       "      <td>0.841494</td>\n",
       "      <td>0.691103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.713872</td>\n",
       "      <td>0.843154</td>\n",
       "      <td>0.672907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.708801</td>\n",
       "      <td>0.832780</td>\n",
       "      <td>0.689776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.767915</td>\n",
       "      <td>0.843983</td>\n",
       "      <td>0.669951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.752052</td>\n",
       "      <td>0.837344</td>\n",
       "      <td>0.685506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.753515</td>\n",
       "      <td>0.835685</td>\n",
       "      <td>0.683190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAMeL-Lab/bert-base-arabic-camelbert-da</td>\n",
       "      <td>0.833195</td>\n",
       "      <td>0.705522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aubmindlab/bert-base-arabertv02-twitter</td>\n",
       "      <td>0.840664</td>\n",
       "      <td>0.713684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qarib/bert-base-qarib</td>\n",
       "      <td>0.836515</td>\n",
       "      <td>0.704911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reemalyami/AraRoBERTa-SA</td>\n",
       "      <td>0.837759</td>\n",
       "      <td>0.691839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Accuracy        F1\n",
       "0  CAMeL-Lab/bert-base-arabic-camelbert-da  0.833195  0.705522\n",
       "3  aubmindlab/bert-base-arabertv02-twitter  0.840664  0.713684\n",
       "5                    qarib/bert-base-qarib  0.836515  0.704911\n",
       "8                 reemalyami/AraRoBERTa-SA  0.837759  0.691839"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "log_file = 'SaudiBank_sentiment_1.txt'\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Model,Accuracy,F1\\n')\n",
    "\n",
    "\n",
    "df = pd.read_csv('benchmarks/data_Saudi_banks.csv', encoding='utf-8', engine='python', sep='\\t') #, quotechar=\"'\"  , quoting=3\n",
    "display(df.columns)\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "display(df[:4])\n",
    "\n",
    "df = df[df['Tweet'] != '']\n",
    "\n",
    "classes = set(df['Final annotation'].values)\n",
    "display(classes)\n",
    "\n",
    "df['Final annotation'] = df['Final annotation'].astype('category')\n",
    "df['label'] = df['Final annotation'].cat.codes\n",
    "\n",
    "\n",
    "df = df[['Tweet', 'label']]\n",
    "\n",
    "\n",
    "classes_num = len(classes)\n",
    "display(classes_num)\n",
    "display(len(df))\n",
    "# display(len(df_test))\n",
    "\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "ds = ds.train_test_split(test_size=0.2)\n",
    "display(ds)\n",
    "\n",
    "# max_sequence_length = 128\n",
    "max_sequence_length = 128\n",
    "\n",
    "models = [ \n",
    "        'aubmindlab/bert-base-arabertv02-twitter',\n",
    "        'CAMeL-Lab/bert-base-arabic-camelbert-da',\n",
    "        'qarib/bert-base-qarib',\n",
    "        'reemalyami/AraRoBERTa-SA',    \n",
    "]\n",
    "\n",
    "for model_name in models:\n",
    "    for i in range(3):\n",
    "        print(f'{model_name}, try:{i}')\n",
    "              \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                              num_labels=classes_num).to('cuda')                                                 \n",
    "        dataset_train = ds['train']\n",
    "        dataset_validation = ds['test']                                                    \n",
    "        \n",
    "      \n",
    "\n",
    "        def preprocess_function(examples):\n",
    "            return tokenizer(examples['Tweet'], truncation=True, padding=\"max_length\",\n",
    "                            max_length=max_sequence_length, add_special_tokens=True)\n",
    "        \n",
    "        \n",
    "        dataset_train = dataset_train.map(preprocess_function, batched=True)\n",
    "        dataset_validation = dataset_validation.map(preprocess_function, batched=True)\n",
    "        \n",
    "       \n",
    "        \n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)    \n",
    "            acc = accuracy_score(labels, predictions)        \n",
    "            f1 = f1_score(labels, predictions, average='macro')   \n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{model_name},{acc},{f1}\\n')\n",
    "            return {'accuracy': acc, 'f1_score': f1}\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        epochs = 5\n",
    "        save_steps = 10000 #save checkpoint every 10000 steps\n",
    "        batch_size = 64\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = 'bert/',\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs = epochs,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            save_steps = save_steps,\n",
    "            save_total_limit = 1, #only save the last 5 checkpoints\n",
    "            fp16=True,\n",
    "            learning_rate = 5e-5,  # 5e-5 is the default\n",
    "            logging_steps = 30, #50_000\n",
    "            evaluation_strategy = 'steps',\n",
    "            # evaluate_during_training = True,\n",
    "            eval_steps = 30\n",
    "            \n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args = training_args,\n",
    "            # data_collator=data_collator,\n",
    "            train_dataset=dataset_train,\n",
    "            eval_dataset=dataset_validation,\n",
    "            compute_metrics = compute_metrics\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # trainer.train(resume_from_checkpoint=True)\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "results = pd.read_csv(log_file)\n",
    "\n",
    "best_results = results.groupby('Model', as_index=False)['F1'].max()\n",
    "\n",
    "best_results = pd.merge(best_results, results, on=['Model', 'F1'])\n",
    "best_results = best_results[['Model', 'Accuracy', 'F1']]\n",
    "best_results = best_results.drop_duplicates()\n",
    "best_results.to_csv('SaudiBank_sentiment_results_1.csv')\n",
    "display(best_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b7f13-c4fa-4355-9192-11d71fbab952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794b705-31a1-45d7-8e88-4017a9c282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382f88d-15fb-48d8-8b29-f328f6817a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb4923-7e46-4c22-a4b7-0321fdc9c707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
